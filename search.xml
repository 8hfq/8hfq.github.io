<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[961复旦大学软件工程专业基础综合]]></title>
    <url>%2F2018%2F07%2F23%2Fcjk9hlv4w0005qufuqtyfdbs3%2F</url>
    <content type="text"><![CDATA[第一部分 数据结构与算法考试题型：问答、分析、编程 总分：60分 一、栈（Stack）、队列（Queue）和向量（Vector）内容: 单链表,双向链表,环形链表,带哨兵节点的链表; 栈的基本概念和性质,栈ADT及其顺序,链接实现;栈的应用;栈与递归; 队列的基本概念和性质,队列ADT及其顺序,链接实现;队列的应用; 向量基本概念和性质;向量ADT及其数组、链接实现; 二、树树的基本概念和术语树是一种非线性的数据结构他是若干结点（A,B,C…等都是结点）的集合，是由唯一的根A和若干颗互不相交的子树组成的。其中每一棵子树又是一棵树，也是由唯一的根结点和若干颗互不相交的子树组成的。由此可知，树的定义是递归的。 树的结点包含一个数据元素以及若干指向其子树的分支。结点拥有的子树数目称为结点的度。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点。除根结点之外，分支结点也称为内部结点。树的度是树内各结点的度的最大值。结点的子树的根称为该结点的孩子。相应地，该结点称为孩子的双亲。同一个双亲的孩子之间互称为兄弟（Sibling）。结点的祖先(Ancestor)是从根到该结点所经分支上的所有结点。结点的层次：结点的层次从根开始定义起，根为第一层，根的孩子为第二层。若某结点在第L层，则其子树的根就在第L+1层。其双亲在同一层的结点互为堂兄弟。树中结点的最大层次称为树的深度或高度(Depth)。如果将树中结点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。森林是m(m&gt;=0)棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。 二叉树的先序,中序,后序,层次序遍历;先序遍历操作过程如下如果二叉树为空树，则什么都不做，否则：1）访问根节点2）先序遍历左子树3）先序遍历右子树对应的算法描述如下 12345678void preorder(BTNode *p)&#123; if(p!=NULL)&#123; Visit(p); preorder(p-&gt;lchild); preorder(p-&gt;rchild); &#125;&#125; 中序遍历操作如下如果二叉树为空树，则什么都不做，否则：1）中序遍历左子树。2）访问根节点。3）中序遍历右子树。对应的算法描述如下 1234567void inorder(BTNode *p)&#123; if(p!=NULL)&#123; preorder(p-&gt;lchild); Visit(p); preorder(p-&gt;rchild); &#125;&#125; 后序遍历操作如下如果二叉树为空树，则什么都不做，否则：1）后序遍历左子树。2）后序遍历右子树。3）访问根节点。对应的算法描述如下 1234567void postorder(BTNode *p)&#123; if(p!=NULL)&#123; preorder(p-&gt;lchild); preorder(p-&gt;rchild); Visit(p); &#125;&#125; 层次遍历如图所示为二叉树的层次遍历，即按照箭头所示方向，按照1，2，3，4的层次顺序对二叉树中的各个结点访问。要进行层次遍历需要建立一个循环队列，先将二叉树头结点入队列，然后出队列，访问该结点，如果他有左子树，则将左子树的根节点入队，如果他有右子树，则将右子树的根节点入队，然后出队列，对出对结点访问，如此反复，直到队列为空为止。得到的算法如下 12345678910111213141516171819202122232425void level(BTNode *p) &#123; int front, rear; BTNode *que[maxSize]; front = rear = 0; BTNode *q; if (p != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = p; while (front != rear) &#123; front = (front + 1) maxSize; q = que[front]; Visit(q); if (q-&gt;lchild != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = q-&gt;lchild; &#125; if (q-&gt;rchild != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = q-&gt;rchild; &#125; &#125; &#125;&#125; 二叉树遍历算法的改进二叉树深度优先遍历算法的非递归实现先序遍历非递归算法出栈时判断是否有孩子，右孩子先入栈，左孩子后入栈，因为对左孩子的访问要先于右孩子中序遍历非递归算法入栈即考虑左孩子是否存在，存在则入，出栈考虑其右孩子是否存在，存在则入。后序遍历非递归算法非递归先序遍历算法中的对左右子树的遍历顺序交换就可以得到逆后序遍历序列，然后将逆后序遍历序列逆序就得到了后序遍历。因此我们需要两个栈 线索二叉树中序线索二叉树线索二叉树(引线二叉树) 的定义如下:一个二叉树通过如下的方法“穿起来”：所有原本为空的右(孩子)指针改为指向该节点在中序序列中的后继，所有原本为空的左(孩子)指针改为指向该节点的中序序列的前驱。线索二叉树能线性地遍历二叉树，从而比递归的 中序遍历更快。使用线索二叉树也能够方便的找到一个节点的父节点，这比显式地使用父亲节点指针或者栈效率更高。这在栈空间有限，或者无法使用存储父节点的栈时很有作用（对于通过深度优先搜索来查找父节点而言)。 考虑这样的例子：一个节点k有一个右孩子r，那么r的左指针可能是指向一个孩子节点，或是一个指回k的线索。如果r有左孩子，这个左孩子同样也应该有一个左孩子或是指回k的线索。对于所有的左孩子同理。因此沿着这些从r发出的左指针，我们最终会找到一个指回k的线索。这种特性是对称的：当q是p的左孩子时，我们可以沿着q的右孩子找到一个指回p的线索。传统的二叉树一般都是以链式存储的结构来表示。这样，二叉树中的每个节点都可以用链表中的一个链节点来存储，每个链节点就包含了若干个指针。但是，这种传统的链式存储结构只能表现出二叉树中节点之间的父子关系，而且不能利用空余的指针来直接得到某个节点的在特定的遍历顺序（先序，中序，后序）中的直接前驱和直接后继。通过分析传统的二叉树链式存储结构表示的二叉树中，存在大量的空闲指针。若能利用这些空指针域来存放指向该节点的直接前驱或是直接后继的指针，则可以进行某些更方便的运算。这些被重新利用起来的空指针就被称为线索，加上了这些线索的二叉树就是线索二叉树。 二叉树及其性质二叉树的定义1）每个结点最多只有2颗子树，即二叉树中节点的度只能为0，1，22）子树有左右顺序之分，不能颠倒。性质1非空二叉树上叶子结点数等于双分支结点数加1性质2二叉树的第i层上最多有$2^i-1$个结点性质3高度或深度为k的二叉树最多有$2^k-1$个结点。换句话说，满二叉树中前k层的结点个数为$2^k-1$性质4有n个结点的完全二叉树，对各结点从上到下，从左到右依次编号（编号范围1~n）则结点之间有如下的关系若i为某结点a的编号则：如果i≠1，则a双亲结点的编号为 ⌊i/2⌋.如果2i≤n，则a左孩子的编号为2i；如果2i&gt;n，则a无左孩子。如果2i+1≤n，则a右孩子的编号为2i+1；如果2i+1&gt;n，则a无右孩子。性质5函数Catalan():给定n个结点，能够构成h(n)中不同的二叉树 $h(n)=Cn=C(2n,n)/(n+1) $注：$C(n,r)=n!/[r!(n-r)!]$性质6具有n(n&gt;0)个结点的完全二叉树的高度为⌊⌋ 普通树与二叉树的转换树转换成二叉树树转换成二叉树的过程如下1）将同一结点的各孩子结点用线串起来2）将每个结点的分支从左到右除了第一个外，其余的都剪掉，整理即可得到 二叉树转换成树二叉树转换为树是树转换为二叉树的逆过程，其步骤是：1）若某结点的左孩子结点存在，将左孩子结点的右孩子结点、右孩子结点的右孩子结点……都作为该结点的孩子结点，将该结点与这些右孩子结点用线连接起来；2）删除原二叉树中所有结点与其右孩子结点的连线；3）整理（1）和（2）两步得到的树，使之结构层次分明。 森林转换成二叉树森林是由若干棵树组成，可以将森林中的每棵树的根结点看作是兄弟，由于每棵树都可以转换为二叉树，所以森林也可以转换为二叉树。 将森林转换为二叉树的步骤是：1）先把每棵树转换为二叉树；2）第一棵二叉树不动，从第二棵二叉树开始，依次把后一棵二叉树的根结点作为前一棵二叉树的根结点的右孩子结点，用线连接起来。当所有的二叉树连接起来后得到的二叉树就是由森林转换得到的二叉树。 二叉树转换成森林二叉树转换为森林比较简单，其步骤如下：1）先把每个结点与右孩子结点的连线删除，得到分离的二叉树；2）把分离后的每棵二叉树转换为树；3）整理第（2）步得到的树，使之规范，这样得到森林。 森林和树的遍历根据树与二叉树的转换关系以及二叉树的遍历定义可以推知，树的先序遍历与其转换的相应的二叉树的先序遍历的结果序列相同；树的后序遍历与其转换的二叉树的中序遍历的结果序列相同；树的层序遍历与其转换的二叉树的后序遍历的结果序列相同。由森林与二叉树的转换关系以及森林与二叉树的遍历定义可知，森林的先序遍历和中序遍历与所转换得到的二叉树的先序遍历和中序遍历的结果序列相同。 树的存储结构,标准形式顺序存储结构树的顺序存储结构最简单直观的是双亲存储结构，用一维数组即可实现。将所有结点存到一个数组中。每个结点都有一个数据域data和一个数值parent指示其双亲在数组中存放的位置。根结点由于没有父结点，parent用-1表示。int tree[maxSize] 链式存储结构1）孩子存储结构孩子存储结构实质上就是图的邻接表存储结构树就是一种特殊的图，把图中的多对多关系删减成一对多关系即可的得到树2）孩子兄弟存储结构树转换成二叉树的过程 完全树(complete tree)的数组形式存储树的应用二叉排序树和平衡二叉树与查找关系密切，因为放到查找一章讲解 Huffman树的定义与应用Huffman树相关的概念1）路径：是指在一棵树中，从一个节点到另一个节点之间的分支构成的通路，如从节点8到节点1的路径如下图所示：2）路径的长度：是指路径上的分支数目，在上图中，路径长度为2。3）树的路径长度：是指从根到每个结点的路径长度之和。4）带权路径长度：结点具有权值，从该结点到根之间的路径长度乘以结点的权值，就是该结点的带权路径长度。5）树的带权路径长度：是指树中所有叶子节点的带权路径之和。6 节点的权：指的是为树中的每一个节点赋予的一个非负的值，如上图中每一个节点中的值 有了如上的概念，对于Huffman树，其定义为：给定n权值作为n个叶子节点，构造一棵二叉树，若这棵二叉树的带权路径长度达到最小，则称这样的二叉树为最优二叉树，也称为Huffman树。 Huffman树的构建给定n个权值，用这n个权值来构建赫夫曼树的算法描述如下：1）将这n个权值分别看成只有根节点的n棵二叉树，将这些二叉树的集合记为F。2）从F中选出两颗根结点的权值最小的树，作为左右子树，构建一棵新的二叉树，新的二叉树的根结点的权值为左右子结点的权值之和。3）从F中删去a,b，加入新构建的树C4）重复2，3步，直到F中只剩下一棵树为止，这棵树就是赫夫曼树。 对于树中节点的结构为： 1234567struct huffman_node&#123; char c; int weight; char huffman_code[LEN]; huffman_node * left; huffman_node * right;&#125;; 对于Huffman树的构建过程为： 1234567891011121314151617181920212223242526272829303132333435363738394041int huffman_tree_create(huffman_node *&amp;root, map&lt;char, int&gt; &amp;word)&#123; char line[MAX_LINE]; vector&lt;huffman_node *&gt; huffman_tree_node; map&lt;char, int&gt;::iterator it_t; for (it_t = word.begin(); it_t != word.end(); it_t++)&#123; // 为每一个节点申请空间 huffman_node *node = (huffman_node *)malloc(sizeof(huffman_node)); node-&gt;c = it_t-&gt;first; node-&gt;weight = it_t-&gt;second; node-&gt;left = NULL; node-&gt;right = NULL; huffman_tree_node.push_back(node); &#125; // 开始从叶节点开始构建Huffman树 while (huffman_tree_node.size() &gt; 0)&#123; // 按照weight升序排序 sort(huffman_tree_node.begin(), huffman_tree_node.end(), sort_by_weight); // 取出前两个节点 if (huffman_tree_node.size() == 1)&#123;// 只有一个根结点 root = huffman_tree_node[0]; huffman_tree_node.erase(huffman_tree_node.begin()); &#125;else&#123; // 取出前两个 huffman_node *node_1 = huffman_tree_node[0]; huffman_node *node_2 = huffman_tree_node[1]; // 删除 huffman_tree_node.erase(huffman_tree_node.begin()); huffman_tree_node.erase(huffman_tree_node.begin()); // 生成新的节点 huffman_node *node = (huffman_node *)malloc(sizeof(huffman_node)); node-&gt;weight = node_1-&gt;weight + node_2-&gt;weight; (node_1-&gt;weight &lt; node_2-&gt;weight)?(node-&gt;left=node_1,node-&gt;right=node_2):(node-&gt;left=node_2,node-&gt;right=node_1); huffman_tree_node.push_back(node); &#125; &#125; return 0;&#125; Huffman树的特点1）权值越大的结点，距离根结点越近。2）树中没有度为1的结点，这类树又叫做正则（严格）二叉树。3）树的带权路径长度最短 Huffman编码常见的.zip压缩文件和.jpeg图片文件的底层技术都用到了赫夫曼编码。例如字符串S=AAABBACCCDEEA A B C D E 5次 2次 3次 1次 2次 以出现的次数为权值，构建一个赫夫曼树，对每个结点的左右分支进行编号，左0右1，从根到每个结点的路径的数字序列即为每个字符的编码，对A~E的赫夫曼编码规则 A B C D E 0 110 10 1110 1111 则H(S)=00011011001010101110111111110上述有赫夫曼树导出每个字符的编码，进而得到整个字符串的编码的过程称为赫夫曼编码。在前缀码中，任一字符的编码串都不是另一字符编码串的前缀，赫夫曼编码产生的是最短前缀码。 赫夫曼n叉树赫夫曼二叉树是赫夫曼n叉树的一种特例，当对于结点数目大于等于2的待处理序列，都可以构造赫夫曼二叉树，但却不一定能构建赫夫曼n叉树，但无法构建时。需要补上权值为0的结点让整个序列凑成可以构造赫夫曼n叉树的序列。 三、查找(search)查找的基本概念查找的定义：给定一个K值，在含有N个记录的表中找出关键字等于K的记录。若找到，则查找成功，返回该记录的信息或者该记录在表中的位置；否则查找失败，返回相关的指示记录。由于查找算法的基本操作是关键字的比较，并且关键字比较次数与待查找关键字有关（对于一个查找表来说，对其中不同的关键字查找，关键字比较的次数一般不同），因此通常把查找过程中对关键字的平均比较次数作为衡量一个算法优劣的标准，平均查找长度用ASL来表示。 对线性关系结构的查找顺序查找基本思路：从表的一端开始，顺序扫描线性表，一次将扫描到的关键字和给定的K值比较。顺序查找法对于顺序表和链表都是适用的，对于顺序表，可以通过数组下标递增来顺序扫描数组中的各个元素；对于链表，则可以通过表结点指针反复执行p=p-&gt;next来扫描表中的各个元素。 12345678int Search(int a[], int n ,int t)&#123; int i; for (int i = 1; i &lt;=n; ++i) &#123; if(a[i]==k) return i; return 0; &#125;&#125; 时间复杂度为0(n) 二分查找基本思路：① 首先确定整个查找区间的中间位置 mid = （ left + right ）/ 2② 用待查关键字值与中间位置的关键字值进行比较； 若相等，则查找成功 若大于，则在后（右）半个区域继续进行折半查找 若小于，则在前（左）半个区域继续进行折半查找③ 对确定的缩小区域再按折半公式，重复上述步骤。 二分查找必须要求1.存储在数组中2.有序排列时间复杂度$O(logn)$ 分块查找(索引顺序表查找)基本思路：对顺序表进行分块查找需要额外建立一个索引表，表中的每一项对应线性表中的一块，每个索引项都由键值分量和链值分量组成，键值分量存放对应快的最大关键字，链值分量存放指向本地第一个元素和最后一个元素的指针。 二叉排序树与平衡二叉树二叉排序树（BST）二叉排序树（BST）的定义和存储结构二叉排序树或者是空树，或者是满足一下性质的二叉树：1）若他的左子树不为空，则左子树上的关键字的值均小于根关键字的值2）若他的右子树不空，则右子树上所有关键字的值均大于根关键字的值3）左右子树有格式一棵二叉排序树 通常采用二叉链表进行存储，其结点类型定义与一般的二叉树类似 12345typedef struct BTNode&#123; int key; struct BTNode *lchild; struct BTNode *rchild;&#125;BTNode; 二叉排序树的基本算法在二元排序树b中查找x的过程为： 1.若b是空树，则搜索失败，否则： 2.若x等于b的根节点的数据域之值，则查找成功；否则： 3.若x小于b的根节点的数据域之值，则搜索左子树；否则： 4.查找右子树。 在二叉排序树中删去一个结点，分三种情况讨论： 1.若*p结点为叶子结点，即PL(左子树)和PR(右子树)均为空树。由于删去叶子结点不破坏整棵树的结构，则只需修改其双亲结点的指针即可。 2.若p结点只有左子树PL或右子树PR，此时只要令PL或PR直接成为其双亲结点f的左子树（当p是左子树）或右子树（当p是右子树）即可，作此修改也不破坏二叉排序树的特性。 3.若p结点的左子树和右子树均不空。在删去p之后，为保持其它元素之间的相对位置不变，可按中序遍历保持有序进行调整。比较好的做法是，找到p的直接前驱（或直接后继）s，用s来替换结点p，然后再删除结点s。 二叉排序树的性能介绍每个结点的Ci为该结点的层次数。最好的情况是二叉排序树的形态和折半查找的判定树相同，其平均查找长度和$logn$成正比$（O(log2(n))）$。最坏情况下，当先后插入的关键字有序时，构成的二叉排序树为一棵斜树，树的深度为n，其平均查找长度为$(n + 1) / 2$。也就是时间复杂度为$O(n)$，等同于顺序查找。因此，如果希望对一个集合按二叉排序树查找，最好是把它构建成一棵平衡的二叉排序树（平衡二叉树）。 平衡二叉树二叉查找树不是严格的O(logN)，当有很多数据灌到我的树中时，我肯定会希望最好是以“完全二叉树”的形式展现，这样我才能做到“查找”是严格的O(logN) 平衡二叉树（AVL）定义父节点的左子树和右子树的高度之差不能大于1，也就是说不能高过1层，否则该树就失衡了，此时就要旋转节点，在编码时，我们可以记录当前节点的高度，比如空节点是-1，叶子节点是0，非叶子节点的height往根节点递增，比如在下图中我们认为树的高度为h=2。 平衡调整AVL树的调整过程很类似于数学归纳法，每次在插入新节点之后都会找到离新插入节点最近的非平衡叶节点，然后对其进行旋转操作以使得树中的每个节点都处于平衡状态。 Left Rotation:左旋,右子树右子节点当新插入的结点为右子树的右子结点时，我们需要进行左旋操作来保证此部分子树继续处于平衡状态。我们应该找到离新插入的结点最近的一个非平衡结点，来以其为轴进行旋转，下面看一个比较复杂的情况： Right Rotation:右旋,左子树左子节点当新插入的结点为左子树的左子结点时，我们需要进行右旋操作来保证此部分子树继续处于平衡状态。 下面看一个比较复杂的情况: Left-Right Rotation:先左旋再右旋,左子树右子节点在某些情况下我们需要进行两次旋转操作，譬如在如下的情况下，某个结点被插入到了左子树的右子结点：我们首先要以A为轴进行左旋操作:然后需要以C为轴进行右旋操作:最终得到的又是一棵平衡树: Right-Left Rotation:先右旋再左旋,右子树左子节点 B-树和B+树的基本概念B-树（B树）的基本概念B-树中所有结点中孩子结点个数的最大值成为B-树的阶，通常用m表示，从查找效率考虑，一般要求m&gt;=3。一棵m阶B-树或者是一棵空树，或者是满足以下条件的m叉树。1）每个结点最多有m个分支（子树）；而最少分支数要看是否为根结点，如果是根结点且不是叶子结点，则至少要有两个分支，非根非叶结点至少有ceil(m/2)个分支，这里ceil代表向上取整。2）如果一个结点有n-1个关键字，那么该结点有n个分支。这n-1个关键字按照递增顺序排列。3）每个结点的结构为： n k1 k2 … knp0 p1 p2 … pn其中，n为该结点中关键字的个数；ki为该结点的关键字且满足ki&lt;ki+1；pi为该结点的孩子结点指针且满足pi所指结点上的关键字大于ki且小于ki+1，p0所指结点上的关键字小于k1，pn所指结点上的关键字大于kn。 4）结点内各关键字互不相等且按从小到大排列。5）叶子结点处于同一层；可以用空指针表示，是查找失败到达的位置。注：平衡m叉查找树是指每个关键字的左侧子树与右侧子树的高度差的绝对值不超过1的查找树，其结点结构与上面提到的B-树结点结构相同，由此可见，B-树是平衡m叉查找树，但限制更强，要求所有叶结点都在同一层。 光看上面的解释可能大家对B-树理解的还不是那么透彻，下面我们用一个实例来进行讲解。上面的图片显示了一棵B-树，最底层的叶子结点没有显示。我们对上面提到的5条特点进行逐条解释：1）结点的分支数等于关键字数+1，最大的分支数就是B-树的阶数，因此m阶的B-树中结点最多有m个分支，所以可以看到，上面的一棵树是一个5-阶B-树。2）因为上面是一棵5阶B-树，所以非根非叶结点至少要有ceil(5/2)=3个分支。根结点可以不满足这个条件，图中的根结点有两个分支。3）如果根结点中没有关键字就没有分支，此时B-树是空树，如果根结点有关键字，则其分支数比大于或等于2，因为分支数等于关键字数+1.4）上图中除根结点外，结点中的关键字个数至少为2，因为分支数至少为3，分支数比关键字数多1，还可以看出结点内关键字都是有序的，并且在同一层中，左边结点内所有关键字均小于右边结点内的关键字，例如，第二层上的两个结点，左边结点内的关键字为15，26，他们均小于右边结点内的关键字39和45.B-树一个很重要的特征是，下层结点内的关键字取值总是落在由上层结点关键字所划分的区间内，具体落在哪个区间内可以由指向它的指针看出。例如，第二层最左边的结点内的关键字划分了三个区间，小于15，15到26，大于26，可以看出其下层中最左边结点内的关键字都小于15，中间结点的关键字在15和26之间，右边结点的关键字大于26.5）上图中叶子结点都在第四层上，代表查找不成功的位置。 B-树的查找操作B-树的查找很简单，是二叉排序树的扩展，二叉排序树是二路查找，B-树是多路查找，因为B-树结点内的关键字是有序的，在结点内进行查找时除了顺序查找外，还可以用折半查找来提升效率。B-树的具体查找步骤如下（假设查找的关键字为key）：1）先让key与根结点中的关键字比较，如果key等于k[i]（k[]为结点内的关键字数组），则查找成功2）若key&lt;k[1]，则到p[0]所指示的子树中进行继续查找（p[]为结点内的指针数组），这里要注意B-树中每个结点的内部结构。3）若key&gt;k[n]，则道p[n]所指示的子树中继续查找。4）若k[i]&lt;key&lt;k[i+1]，则沿着指针p[I]所指示的子树继续查找。5）如果最后遇到空指针，则证明查找不成功。 拿上面的二叉树进行举例，比如我们想要查找关键字42，下图加粗的部分显示了查找的路径： B-树的插入与二叉排序树一样，B-树的创建过程也是将关键字逐个插入到树中的过程。在进行插入之前，要确定一下每个结点中关键字个数的范围，如果B-树的阶数为m，则结点中关键字个数的范围为ceil(m/2)-1 ~ m-1个。对于关键字的插入，需要找到插入位置。在B-树的查找过程中，当遇到空指针时，则证明查找不成功，同时也找到了插入位置，即根据空指针可以确定在最底层非叶结点中的插入位置，为了方便，我们称最底层的非叶结点为终端结点，由此可见，B-树结点的插入总是落在终端结点上。在插入过程中有可能破坏B-树的特征，如新关键字的插入使得结点中关键字的个数超过规定个数，这是要进行结点的拆分。接下来，我们以关键字序列{1,2,6,7,11,4,8,13,10,5,17,9,16,20,3,12,14,18,19,15}创建一棵5阶B-树，我们将详细体会B-树的插入过程。（1）确定结点中关键字个数范围由于题目要求建立5阶B-树，因此关键字的个数范围为2～4（2）根结点最多可以容纳4个关键字，依次插入关键字1、2、6、7后的B-树如下图所示：（3）当插入关键字11的时候，发现此时结点中关键字的个数变为5，超出范围，需要拆分，去关键字数组中的中间位置，也就是k[3]=6，作为一个独立的结点，即新的根结点，将关键字6左、右关键字分别做成两个结点，作为新根结点的两个分支，此时树如下图所示： （4）新关键字总是插在叶子结点上，插入关键字4、8、13之后树为： （5）关键字10需要插入在关键字8和11之间，此时又会出现关键字个数超出范围的情况，因此需要拆分。拆分时需要将关键字10纳入根结点中，并将10左右的关键字做成两个新的结点连在根结点上。插入关键字10并经过拆分操作后的B-树如下图： （6）插入关键字5、17、9、16之后的B-树如图所示： （7）关键字20插入在关键字17以后，此时会造成结点关键字个数超出范围，需要拆分，方法同上，树为： （8）按照上述步骤依次插入关键字3、12、14、18、19之后B-树如下图所示： （9）插入最后一个关键字15，15应该插入在14之后，此时会出现关键字个数超出范围的情况，则需要进行拆分，将13并入根结点，13并入根结点之后，又使得根结点的关键字个数超出范围，需要再次进行拆分，将10作为新的根结点，并将10左、右关键字做成两个新结点连接到新根结点的指针上，这种插入一个关键字之后出现多次拆分的情况称为连锁反应，最终形成的B-树如下图所示： B-树的删除对于B-树关键字的删除，需要找到待删除的关键字，在结点中删除关键字的过程也有可能破坏B-树的特性，如旧关键字的删除可能使得结点中关键字的个数少于规定个数，这是可能需要向其兄弟结点借关键字或者和其孩子结点进行关键字的交换，也可能需要进行结点的合并，其中，和当前结点的孩子进行关键字交换的操作可以保证删除操作总是发生在终端结点上。 我们用刚刚生成的B-树作为例子，一次删除8、16、15、4这4个关键字。（1）删除关键字8、16。关键字8在终端结点上，并且删除后其所在结点中关键字的个数不会少于2，因此可以直接删除。关键字16不在终端结点上，但是可以用17来覆盖16，然后将原来的17删除掉，这就是上面提到的和孩子结点进行关键字交换的操作。这里不能用15和16进行关键字交换，因为这样会导致15所在结点中关键字的个数小于2。因此，删除8和16之后B-树如下图所示： （2）删除关键字15，15虽然也在终端结点上，但是不能直接删除，因为删除后当前结点中关键字的个数小于2。这是需要向其兄弟结点借关键字，显然应该向其右兄弟来借关键字，因为左兄弟的关键字个数已经是下限2.借关键字不能直接将18移到15所在的结点上，因为这样会使得15所在的结点上出现比17大的关键字，所以正确的借法应该是先用17覆盖15，在用18覆盖原来的17，最后删除原来的18，删除关键字15后的B-树如下图所示： （3）删除关键字4，4在终端结点上，但是此时4所在的结点的关键字个数已经到下限，需要借关键字，不过可以看到其左右兄弟结点已经没有多余的关键字可借。所以就需要进行关键字的合并。可以先将关键字4删除，然后将关键字5、6、7、9进行合并作为一个结点链接在关键字3右边的指针上，也可以将关键字1、2、3、5合并作为一个结点链接在关键字6左边的指针上，如下图所示： 显然上述两种情况下都不满足B-树的规定，即出现了非根的双分支结点，需要继续进行合并，合并后的B-树如下图所示： 有时候删除的结点不在终端结点上，我们首先需要将其转化到终端结点上，然后再按上面的各种情况进行删除。在讲述这种情况下的删除方法之前，要引入一个相邻关键字的概念，对于不在终端结点的关键字a，它的相邻关键字为其左子树中值最大的关键字或者其右子树中值最小的关键字。找a的相邻关键字的方法为：沿着a的左指针来到其子树根结点，然后沿着根结点中最右端的关键字的右指针往下走，用同样的方法一直走到叶结点上，叶结点上的最右端的关键字即为a的相邻关键字（这里找的是a左边的相邻关键字，我们可以用同样的思路找到a右边的相邻关键字）。可以看到下图中a的相邻关键字是d和e，要删除关键字a，可以用d来取代a，然后按照上面的情况删除叶子结点上的d即可。 B+树的基本概念可以看到，m阶B+树和B-树的差别主要体现在：1）在B+树中，具有n个关键字的结点有n个分支，而在B-树中，具有n个关键字的结点含有n+1个关键字。2）在B+树中，每个结点（除根结点外）中的关键字个数n的取值为ceil(m/2) &lt;= n &lt;=m,根结点的取值范围为1&lt;=n&lt;=m，他们的取值范围分别是ceil(m/2) -1&lt;= n &lt;=m-1和1&lt;=n&lt;=m-1。3）在B+树中叶子结点包含信息，并且包含了全部关键字，叶子结点引出的指针指向记录。4）在B+树中的所有非叶子结点仅起到一个索引的作用，即结点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址，而在B-树中，每个关键字对应一个记录的存储地址。 散列表（哈希表） 哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 根据给定的关键字来计算出关键字在表中的地址 散列表的建立方法以及冲突解决方法 Hash查找法,常见的Hash函数(直接定址法,随机数法),hash冲突的概念, 解决冲突的方法(开散列方法/拉链法,闭散列方法/开址定址法),二次聚集现象; 优先队列与堆,堆的定义,堆的生成,调整算法;范围查询; 四、排序插入类排序直接插入排序直接插入排序的思想是每一步将一个带排序的记录，插入到前面已经排序好的有序序列中去，直到插完所有元素为止。 1234567891011121314void InsertSort(int R[],int n)&#123; int i,j; int temp; //将代插入关键字暂存在temp中 for (i=1;i&lt;n;i++)&#123; temp = R[i]; j =i-1; //循环从待排关键字之前的关键字开始扫描，如果大于待排关键字，则后移一位 while (j&gt;=0&amp;&amp;temp&lt;R[j])&#123; R[j+1]=R[j]; --j; &#125; R[j+1] = temp; //找到插入位置 &#125;&#125; 算法性能分析时间复杂度分析 选取最内层循环R[j+1]=R[j];作为基本操作1）考虑最坏情况，整个序列是逆序的，基本操作次数为n(n-1)/2时间复杂度为$O(n^2)$ 空间复杂度分析 算法所需的辅助储存空间不随待排序规模的变化二变化，是个常量，因此空间复杂度为$O(1)$ 折半插入排序折半插入排序思想顺序地把待排序的序列中的各个元素按其关键字的大小，通过折半查找插入到已排序的序列的适当位置。 123456789101112131415161718void BinaryInsertSort(int R[], int n) &#123; int i, j, temp, m, low, high; for (i = 1; i &lt; n; i++) &#123; temp = R[i]; low = 0; high = i - 1; while (low &lt;= high) &#123; m = (low + high) / 2; if (R[m] &gt; temp) high = m - 1; else low = m + 1; &#125; &#125; for (j = i - 1; j &gt;= high + 1; j--) R[j + 1] = R[j]; R[j + 1] = temp;&#125; 算法性能分析折半查找只是减少了比较次数，但是元素的移动次数不变。折半插入排序平均时间复杂度为$O(n^2)$；空间复杂度为O(1)；是稳定的排序算法。 希尔排序希尔排序思想希尔排序(Shell Sort)是插入排序的一种，它是针对直接插入排序算法的改进。该方法又称缩小增量排序，因DL．Shell于1959年提出而得名。 希尔排序实质上是一种分组插入方法。它的基本思想是：对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 算法性能分析希尔排序时间复杂度希尔排序的时间复杂度与增量(即，步长gap)的选取有关。例如，当增量为1时，希尔排序退化成了直接插入排序，此时的时间复杂度为$O(n²)$，而Hibbard增量的希尔排序的时间复杂度为$O(N^{1.5})$。空间复杂度同直接插入排序一样为O(1)。 希尔排序稳定性希尔排序是不稳定的算法，它满足稳定算法的定义。对于相同的两个数，可能由于分在不同的组中而导致它们的顺序发生变化。算法稳定性 – 假设在数列中存在a[i]=a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 交换类排序冒泡排序冒泡排序思想冒泡排序(Bubble Sort)，又被称为气泡排序或泡沫排序。 它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止！ 1234567891011121314151617void BubbleSort(int R[],int n) &#123; &#123; int i, j; int flag; // 标记 for (i = n - 1; i &gt; 0; i--) &#123; flag = 0; // 将a[0...i]中最大的数据放在末尾 for (j = 0; j &lt; i; j++) &#123; if (R[j] &gt; R[j + 1]) swap(R[j], R[j + 1]); flag = 1; &#125; if (flag==0) break; &#125; &#125;&#125; 算法性能分析冒泡排序时间空间复杂度冒泡排序的时间复杂度是$O(n^2)$。假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢？N-1次！因此，冒泡排序的时间复杂度$O(n^2)$。额外的辅助空间只有一个flag，因此空间复杂度为$O(1)$。 冒泡排序稳定性冒泡排序是稳定的算法，它满足稳定算法的定义。算法稳定性 – 假设在数列中存在a[i]=a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 快速排序快速排序思想快速排序(Quick Sort)使用分治法策略。它的基本思想是：选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 快速排序流程：(1) 从数列中挑出一个基准值。(2) 将所有比基准值小的摆放在基准前面，所有比基准值大的摆在基准的后面(相同的数可以到任一边)；在这个分区退出之后，该基准就处于数列的中间位置。(3) 递归地把”基准值前面的子数列”和”基准值后面的子数列”进行排序。 1234567891011121314151617181920212223void QuickSort(int R[],int low,int high)&#123; int temp; int i =low,j=high; if(low&lt;high)&#123; temp=R[low]; while(i!=j)&#123; while(j&gt;i&amp;&amp;R[j]&gt;=temp) --j; if(i&lt;j) &#123; R[i] = R[j]; ++i; &#125; while (i&lt;j&amp;&amp;R[i]&lt;temp) ++i; if(i&gt;j)&#123; R[j]=R[i]; --j; &#125; &#125; R[i] = temp; QuickSort(R,low,i-1); QuickSort(R,i+1,high); &#125;&#125; 算法性能分析快速排序稳定性快速排序是不稳定的算法，它不满足稳定算法的定义。算法稳定性 – 假设在数列中存在a[i]=a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 快速排序时间复杂度快速排序的时间复杂度在最坏情况下是$O(n^2)$，平均的时间复杂度是$O(nlog_2n)$。这句话很好理解：假设被排序的数列中有N个数。遍历一次的时间复杂度是O(N)，需要遍历多少次呢？至少lg(N+1)次，最多N次。(01) 为什么最少是lg(N+1)次？快速排序是采用的分治法进行遍历的，我们将它看作一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的定义，它的深度至少是lg(N+1)。因此，快速排序的遍历次数最少是lg(N+1)次。(02) 为什么最多是N次？这个应该非常简单，还是将快速排序看作一棵二叉树，它的深度最大是N。因此，快读排序的遍历次数最多是N次。 空间复杂度为$o(log_2n)$，快速排序是递归进行的，递归需要栈的辅助，因此他需要的辅助空间比前几类排序算法大。 选择类排序简单选择排序从头到尾顺序扫描序列，找出一个最小的一个关键字和第一个关键字交换，接着从剩下的关键字中继续这种选择和交换，最终使序列有序。 1234567891011121314void SelectSort(int R[],int n)&#123; int i,j,k; int temp; for (int i = 0; i &lt; n; ++i) &#123; k=i; for (j = i+1; j &lt;n ; ++j) if(R[k]&gt;R[j]) k=j; temp=R[i]; R[i]=R[k]; R[k]=temp; &#125; &#125;&#125; 性能分析时间复杂度$O(n^2)$ 空间复杂度$O(1)$ 堆排序最大堆进行升序排序的基本思想：① 初始化堆：将数列a[1…n]构造成最大堆。② 交换数据：将a[1]和a[n]交换，使a[n]是a[1…n]中的最大值；然后将a[1…n-1]重新调整为最大堆。 接着，将a[1]和a[n-1]交换，使a[n-1]是a[1…n-1]中的最大值；然后将a[1…n-2]重新调整为最大值。 依次类推，直到整个数列都是有序的。 堆排序时间复杂度堆排序的时间复杂度是$O(nlog_2 n)$。假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢？堆排序是采用的二叉堆进行排序的，二叉堆就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的定义，它的深度至少是lg(N+1)。最多是多少呢？由于二叉堆是完全二叉树，因此，它的深度最多也不会超过lg(2N)。因此，遍历一趟的时间复杂度是O(N)，而遍历次数介于lg(N+1)和lg(2N)之间；因此得出它的时间复杂度是$O(nlog_2 n)$。 空间复杂度 为O(1). 堆排序稳定性堆排序是不稳定的算法，它不满足稳定算法的定义。它在交换数据的时候，是比较父结点和子节点之间的数据，所以，即便是存在两个数值相等的兄弟节点，它们的相对顺序在排序也可能发生变化。 归并排序归并排序思想 从下往上的归并排序：将待排序的数列分成若干个长度为1的子数列，然后将这些数列两两合并；得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将它们两两合并；直接合并成一个数列为止。这样就得到了我们想要的排序结果。(参考下面的图片) 从上往下的归并排序：它与”从下往上”在排序上是反方向的。它基本包括3步：① 分解 – 将当前区间一分为二，即求分裂点 mid = (low + high)/2;② 求解 – 递归地对两个子区间a[low…mid] 和 a[mid+1…high]进行归并排序。递归的终结条件是子区间长度为1。③ 合并 – 将已排序的两个子区间a[low…mid]和 a[mid+1…high]归并为一个有序的区间a[low…high]。 性能分析归并排序时间复杂度归并排序的时间复杂度是$O(nlog_2 N)$假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢？归并排序的形式就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的可以得出它的时间复杂度是$O(nlog_2 N)$。空间复杂度因归并排序需要转存整个待排序列，因此空间复杂度为O（n）归并排序稳定性归并排序是稳定的算法，它满足稳定算法的定义。 基数排序基数排序思想基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是：将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 算法性能时间复杂度 $O(d(n+r_d))$空间复杂度$(r_d)$ 排序算法性能对比 五、图图的基本概念一个图(G)定义为一个偶对(V,E) ，记为G=(V,E) 。其中： V是顶点(Vertex)的非空有限集合，记为V(G)；E是无序集V&amp;V的一个子集，记为E(G) ，其元素是图的弧(Arc)。 1.图图由结点的有穷集合V和边的集合E组成，为了与树形结构进行区别，在图结构中常常将结点称为顶点，边是顶点的有序偶对。若两个顶点之间存在一条边，则表示这两个顶点具有相邻关系。 2.有向图和无向图有向图(Digraph)： 若图G的关系集合E(G)中，顶点偶对&lt;v,w&gt;的v和w之间是有序的，称图G是有向图。 无向图(Undigraph)： 若图G的关系集合E(G)中，顶点偶对&lt;v,w&gt;的v和w之间是无序的，称图G是无向图。 3.弧在有向图中，若 &lt;v,w&gt;(G) ，表示从顶点v到顶点w有一条弧。 其中：v称为弧尾(tail)或始点(initial node)，w称为弧头(head)或终点(terminal node) 。 4.顶点的度，入度和出度无向图中，顶点 v 的度是指和 v 相关联的边的数目有向图中，以顶点 v 为弧头的弧的数目称为顶点 v 的入度，以顶点 v 为弧尾的弧的数目称为顶点 v 的出度 5.有向完全图和无向完全图有向图中每两个顶点之间都有两条方向相反的边连接的图称为有向完全图。弧数为 n(n -1)（结点为 n）无向图中每一对不同顶点恰有一条边相连的图称为无向完全图。边数为n(n−1)2（结点数为 n） 6.路径和路径长度从顶点 v 经过一系列的边或弧到达顶点 w ，则称这一系列的边或弧为顶点v 到顶点 w 的路径。路径长度是指路径上边的数目。 7.简单路径序列中顶点不重复出现的路径称为简单路径 8.回路若一条路径中第一个顶点和最后一个顶点相同，则这条路径是一条回路 9.连通,连通图和连通分量在无向图中，如果从顶点 v 到顶点 w 有路径，则称顶点 v 和 顶点 w 是连通的。如果对于图中的任意两个顶点都是连同的，则称为连通图。无向图中的极大连通子图为其连通分量。 10.强连通图和强连通分量在有向图中，如果对每一对顶点 v 、w 从v 和 从w到v都有路径，则称该有向图是强连通图。有向图中的极大强连通子图称为有向图的强连通分量。 11.权和网图中每条边都可以附带一个数，这种与边相关的数称为权，权可以表示从一个顶点到另一个顶点的距离或者花费的代价。边上带权的图称为带权图。 图的储存结构邻接矩阵邻接矩阵是表示顶点之间相邻关系的矩阵，存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组（称为邻接矩阵）存储图中的边或弧的信息。 从上面可以看出，无向图的边数组是一个对称矩阵。所谓对称矩阵就是n阶矩阵的元满足aij = aji。即从矩阵的左上角到右下角的主对角线为轴，右上角的元和左下角相对应的元全都是相等的。矩阵中“1”的个数为图中总边数的两倍，矩阵图中第i行和第i列元素之和即为顶点i的度对于有向图，矩阵中“1”的个数即为图的边数，矩阵中第i行的元素之和即为顶点i的出度，第j列的元素之和即为顶点j的入度 有权有向图中，无边的话0变成无限大，1变成权值 邻接表邻接矩阵是不错的一种图存储结构，但是，对于边数相对顶点较少的图，这种结构存在对存储空间的极大浪费。因此，找到一种数组与链表相结合的存储方法称为邻接表。邻接表的处理方法是这样的：（1）图中顶点用一个一维数组存储，当然，顶点也可以用单链表来存储，不过，数组可以较容易的读取顶点的信息，更加方便。（2）图中每个顶点vi的所有邻接点构成一个线性表，由于邻接点的个数不定，所以，用单链表存储，无向图称为顶点vi的边表，有向图则称为顶点vi作为弧尾的出边表。例如，下图就是一个无向图的邻接表的结构。 图的遍历深度优先搜索遍历图的深度优先搜索遍历（DFS）类似于二叉树的先序遍历。基本思路：假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。 123456789101112131415int visit[maxSize];/* V是起点编号，visit[]是一个全局数组，作为顶点的访问标记，初始时所有元素均为0， * 表示所有顶点都未被访问，因为图中存在回路，当前经过的点在将来还有可能再次经过， * 所以要对每个顶点进行标记，以免重复访问，*/void DFS(AGraph *G,int v)&#123; ArcNode *p; visit[v]=1; Visit(v); p = G-&gt;adjlist[v].firstarc;//p指向顶点v的第一条边 while(p!=NULL)&#123; if(visit[p-&gt;adjvex]==0) DFS(G,p-&gt;adjvex); p=p-&gt;nextarc; &#125;&#125; 无向图的深度优先搜索下面以”无向图”为例，来对深度优先搜索进行演示。对上面的图进行深度优先遍历，从顶点A开始。因此访问顺序是：A -&gt; C -&gt; B -&gt; D -&gt; F -&gt; G -&gt; E 有向图的深度优先搜索下面以”有向图”为例，来对深度优先搜索进行演示。对上面的图进行深度优先遍历，从顶点A开始。因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; D -&gt; F -&gt; G 广度优先搜索遍历广度优先搜索算法（BFS）类似于树的层次遍历基本思想：从图中某顶点v出发，在访问了v之后依次访问v的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使得“先被访问的顶点的邻接点先于后被访问的顶点的邻接点被访问，直至图中所有已被访问的顶点的邻接点都被访问到。如果此时图中尚有顶点未被访问，则需要另选一个未曾被访问过的顶点作为新的起始点，重复上述过程，直至图中所有顶点都被访问到为止。换句话说，广度优先搜索遍历图的过程是以v为起点，由近至远，依次访问和v有路径相通且路径长度为1,2…的顶点。 1234567891011121314151617181920212223242526void BFS(AGraph *G, int v ,int visit[maxSize])&#123; ArcNode * p; int que[maxSize],front=0,rear=0; itn j; Visit(v); visit[v]=1; rear=(rear+1)%maxSize; que[rear]=v; while(front!=rear) &#123; front=(front+1)%maxSize; j=que[front]; p = G-&gt;adjlist[j].firstarc; while (p!=NULL)&#123; if (visit[p-&gt;adjvex]==0) &#123; Visit(p-&gt;adjvex); visit[p-&gt;adjvex]=1; rear = (rear+1)%maxSize; que[rear] = p-&gt;adjvex; &#125; p = p-&gt;nextarc; &#125; &#125;&#125; 无向图的广度优先搜索因此访问顺序是：A -&gt; C -&gt; D -&gt; F -&gt; B -&gt; G -&gt; E 有向图的广度优先搜索因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; F -&gt; D -&gt; G 最小（代价）生成树最小生成树：在含有n个顶点的连通图中选择n-1条边，构成一颗极小连通子图，并使该连通子图中n-1条边上权值之和达到最小，则称其为连通网的最小生成树。例如，对于如上图G4所示的连通网可以有多棵权值总和不相同的生成树。 普里姆（Prim）算法普里姆(Prim)算法思想是用来求加权连通图的最小生成树的算法。基本思想对于图G而言，V是所有顶点的集合；现在，设置两个新的集合U和T，其中U用于存放G的最小生成树中的顶点，T存放G的最小生成树中的边。 从所有uЄU，vЄ(V-U) (V-U表示出去U的所有顶点)的边中选取权值最小的边(u, v)，将顶点v加入集合U中，将边(u, v)加入集合T中，如此不断重复，直到U=V为止，最小生成树构造完毕，这时集合T中包含了最小生成树中的所有边。此时，最小生成树构造完成！它包括的顶点依次是：A B F E D C G。 基本定义代码12345678public class MatrixUDG &#123; private char[] mVexs; // 顶点集合 private int[][] mMatrix; // 邻接矩阵 private static final int INF = Integer.MAX_VALUE; // 最大值 ...&#125; MatrixUDG是邻接矩阵对应的结构体。mVexs用于保存顶点，mEdgNum用于保存边数，mMatrix则是用于保存矩阵信息的二维数组。例如，mMatrix[i][j]=1，则表示”顶点i(即mVexs[i])”和”顶点j(即mVexs[j])”是邻接点；mMatrix[i][j]=0，则表示它们不是邻接点。 普里姆算法代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/* * prim最小生成树 * * 参数说明： * start -- 从图中的第start个元素开始，生成最小树 */public void prim(int start) &#123; int num = mVexs.length; // 顶点个数 int index=0; // prim最小树的索引，即prims数组的索引 char[] prims = new char[num]; // prim最小树的结果数组 int[] weights = new int[num]; // 顶点间边的权值 // prim最小生成树中第一个数是&quot;图中第start个顶点&quot;，因为是从start开始的。 prims[index++] = mVexs[start]; // 初始化&quot;顶点的权值数组&quot;， // 将每个顶点的权值初始化为&quot;第start个顶点&quot;到&quot;该顶点&quot;的权值。 for (int i = 0; i &lt; num; i++ ) weights[i] = mMatrix[start][i]; // 将第start个顶点的权值初始化为0。 // 可以理解为&quot;第start个顶点到它自身的距离为0&quot;。 weights[start] = 0; for (int i = 0; i &lt; num; i++) &#123; // 由于从start开始的，因此不需要再对第start个顶点进行处理。 if(start == i) continue; int j = 0; int k = 0; int min = INF; // 在未被加入到最小生成树的顶点中，找出权值最小的顶点。 while (j &lt; num) &#123; // 若weights[j]=0，意味着&quot;第j个节点已经被排序过&quot;(或者说已经加入了最小生成树中)。 if (weights[j] != 0 &amp;&amp; weights[j] &lt; min) &#123; min = weights[j]; k = j; &#125; j++; &#125; // 经过上面的处理后，在未被加入到最小生成树的顶点中，权值最小的顶点是第k个顶点。 // 将第k个顶点加入到最小生成树的结果数组中 prims[index++] = mVexs[k]; // 将&quot;第k个顶点的权值&quot;标记为0，意味着第k个顶点已经排序过了(或者说已经加入了最小树结果中)。 weights[k] = 0; // 当第k个顶点被加入到最小生成树的结果数组中之后，更新其它顶点的权值。 for (j = 0 ; j &lt; num; j++) &#123; // 当第j个节点没有被处理，并且需要更新时才被更新。 if (weights[j] != 0 &amp;&amp; mMatrix[k][j] &lt; weights[j]) weights[j] = mMatrix[k][j]; &#125; &#125; // 计算最小生成树的权值 int sum = 0; for (int i = 1; i &lt; index; i++) &#123; int min = INF; // 获取prims[i]在mMatrix中的位置 int n = getPosition(prims[i]); // 在vexs[0...i]中，找出到j的权值最小的顶点。 for (int j = 0; j &lt; i; j++) &#123; int m = getPosition(prims[j]); if (mMatrix[m][n]&lt;min) min = mMatrix[m][n]; &#125; sum += min; &#125; // 打印最小生成树 System.out.printf(&quot;PRIM(%c)=%d: &quot;, mVexs[start], sum); for (int i = 0; i &lt; index; i++) System.out.printf(&quot;%c &quot;, prims[i]); System.out.printf(&quot;\n&quot;);&#125; 普里姆算法时间复杂度分析观察代码发现，普里姆算法主要部分是一个双重循环，外层循环内有两个并列的单层循环，单层循环内的操作都是常量级别的，其执行次数为n的平方，因此普里姆算法的时间复杂度为O(n$^2$) 克鲁斯卡尔（Kruskal）算法克鲁斯卡尔算法思想克鲁斯卡尔(Kruskal)算法，是用来求加权连通图的最小生成树的算法。基本思想：按照权值从小到大的顺序选择n-1条边，并保证这n-1条边不构成回路。具体做法：首先构造一个只含n个顶点的森林，然后依权值从小到大从连通网中选择边加入到森林中，并使森林中不产生回路，直至森林变成一棵树为止。此时，最小生成树构造完成！它包括的边依次是：&lt;E,F&gt; &lt;C,D&gt; &lt;D,E&gt; &lt;B,F&gt; &lt;E,G&gt; &lt;A,B&gt;。 根据前面介绍的克鲁斯卡尔算法的基本思想和做法，我们能够了解到，克鲁斯卡尔算法重点需要解决的以下两个问题：问题一 对图的所有边按照权值大小进行排序。问题二 将边添加到最小生成树中时，怎么样判断是否形成了回路。 问题一很好解决，采用排序算法进行排序即可。 问题二，处理方式是：记录顶点在”最小生成树”中的终点，顶点的终点是”在最小生成树中与它连通的最大顶点”(关于这一点，后面会通过图片给出说明)。然后每次需要将一条边添加到最小生存树时，判断该边的两个顶点的终点是否重合，重合的话则会构成回路。 以下图来进行说明：(01) C的终点是F。(02) D的终点是F。(03) E的终点是F。(04) F的终点是F。关于终点，就是将所有顶点按照从小到大的顺序排列好之后；某个顶点的终点就是”与它连通的最大顶点”。 因此，接下来，虽然&lt;C,E&gt;是权值最小的边。但是C和E的重点都是F，即它们的终点相同，因此，将&lt;C,E&gt;加入最小生成树的话，会形成回路。这就是判断回路的方式。 基本定义代码123456789101112// 边的结构体private static class EData &#123; char start; // 边的起点 char end; // 边的终点 int weight; // 边的权重 public EData(char start, char end, int weight) &#123; this.start = start; this.end = end; this.weight = weight; &#125;&#125;; EData是邻接矩阵边对应的结构体。123456789public class MatrixUDG &#123; private int mEdgNum; // 边的数量 private char[] mVexs; // 顶点集合 private int[][] mMatrix; // 邻接矩阵 private static final int INF = Integer.MAX_VALUE; // 最大值 ...&#125; MatrixUDG是邻接矩阵对应的结构体。mVexs用于保存顶点，mEdgNum用于保存边数，mMatrix则是用于保存矩阵信息的二维数组。例如，mMatrix[i][j]=1，则表示”顶点i(即mVexs[i])”和”顶点j(即mVexs[j])”是邻接点；mMatrix[i][j]=0，则表示它们不是邻接点。 克鲁斯卡尔算法代码123456789101112131415161718192021222324252627282930313233343536/* * 克鲁斯卡尔（Kruskal)最小生成树 */public void kruskal() &#123; int index = 0; // rets数组的索引 int[] vends = new int[mEdgNum]; // 用于保存&quot;已有最小生成树&quot;中每个顶点在该最小树中的终点。 EData[] rets = new EData[mEdgNum]; // 结果数组，保存kruskal最小生成树的边 EData[] edges; // 图对应的所有边 // 获取&quot;图中所有的边&quot; edges = getEdges(); // 将边按照&quot;权&quot;的大小进行排序(从小到大) sortEdges(edges, mEdgNum); for (int i=0; i&lt;mEdgNum; i++) &#123; int p1 = getPosition(edges[i].start); // 获取第i条边的&quot;起点&quot;的序号 int p2 = getPosition(edges[i].end); // 获取第i条边的&quot;终点&quot;的序号 int m = getEnd(vends, p1); // 获取p1在&quot;已有的最小生成树&quot;中的终点 int n = getEnd(vends, p2); // 获取p2在&quot;已有的最小生成树&quot;中的终点 // 如果m!=n，意味着&quot;边i&quot;与&quot;已经添加到最小生成树中的顶点&quot;没有形成环路 if (m != n) &#123; vends[m] = n; // 设置m在&quot;已有的最小生成树&quot;中的终点为n rets[index++] = edges[i]; // 保存结果 &#125; &#125; // 统计并打印&quot;kruskal最小生成树&quot;的信息 int length = 0; for (int i = 0; i &lt; index; i++) length += rets[i].weight; System.out.printf(&quot;Kruskal=%d: &quot;, length); for (int i = 0; i &lt; index; i++) System.out.printf(&quot;(%c,%c) &quot;, rets[i].start, rets[i].end); System.out.printf(&quot;\n&quot;);&#125; 克鲁斯卡尔算法时间复杂度分析算法时间花费主要在函数sort()和单层循环上。循环是线性级的，可以认为算法时间主要花费在sort()上，因为排序算法时间复杂度一般大于常量级，因此，克鲁斯卡尔算法的时间复杂度主要由选取的排序算法决定，排序算法所处理的数据的规模由图的边e决定，与顶点无关，因此克鲁斯卡尔算法适用于稀疏图。 最短路径迪杰斯特拉算法（Dijkstra）迪杰斯特拉(Dijkstra)算法是典型最短路径算法，用于计算一个节点到其他节点的最短路径。它的主要特点是以起始点为中心向外层层扩展(广度优先搜索思想)，直到扩展到终点为止。 迪杰特斯拉算法基本思想通过Dijkstra计算图G中的最短路径时，需要指定起点s(即从顶点s开始计算)。此外，引进两个集合S和U。S的作用是记录已求出最短路径的顶点(以及相应的最短路径长度)，而U则是记录还未求出最短路径的顶点(以及该顶点到起点s的距离)。初始时，S中只有起点s；U中是除s之外的顶点，并且U中顶点的路径是”起点s到该顶点的路径”。然后，从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 然后，再从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 … 重复该操作，直到遍历完所有顶点。 操作步骤(1) 初始时，S只包含起点s；U包含除s外的其他顶点，且U中顶点的距离为”起点s到该顶点的距离”[例如，U中顶点v的距离为(s,v)的长度，然后s和v不相邻，则v的距离为∞]。(2) 从U中选出”距离最短的顶点k”，并将顶点k加入到S中；同时，从U中移除顶点k。(3) 更新U中各个顶点到起点s的距离。之所以更新U中顶点的距离，是由于上一步中确定了k是求出最短路径的顶点，从而可以利用k来更新其它顶点的距离；例如，(s,v)的距离可能大于(s,k)+(k,v)的距离。(4) 重复步骤(2)和(3)，直到遍历完所有顶点。单纯的看上面的理论可能比较难以理解，下面通过实例来对该算法进行说明。 基本定义代码12345678910111213141516// 邻接矩阵typedef struct _graph&#123; char vexs[MAX]; // 顶点集合 int vexnum; // 顶点数 int edgnum; // 边数 int matrix[MAX][MAX]; // 邻接矩阵&#125;Graph, *PGraph;// 边的结构体typedef struct _EdgeData&#123; char start; // 边的起点 char end; // 边的终点 int weight; // 边的权重&#125;EData; Graph是邻接矩阵对应的结构体。vexs用于保存顶点，vexnum是顶点数，edgnum是边数；matrix则是用于保存矩阵信息的二维数组。例如，matrix[i][j]=1，则表示”顶点i(即vexs[i])”和”顶点j(即vexs[j])”是邻接点；matrix[i][j]=0，则表示它们不是邻接点。EData是邻接矩阵边对应的结构体。 迪杰斯特拉算法代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/* * Dijkstra最短路径。 * 即，统计图(G)中&quot;顶点vs&quot;到其它各个顶点的最短路径。 * * 参数说明： * G -- 图 * vs -- 起始顶点(start vertex)。即计算&quot;顶点vs&quot;到其它顶点的最短路径。 * prev -- 前驱顶点数组。即，prev[i]的值是&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径所经历的全部顶点中，位于&quot;顶点i&quot;之前的那个顶点。 * dist -- 长度数组。即，dist[i]是&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径的长度。 */void dijkstra(Graph G, int vs, int prev[], int dist[])&#123; int i,j,k; int min; int tmp; int flag[MAX]; // flag[i]=1表示&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径已成功获取。 // 初始化 for (i = 0; i &lt; G.vexnum; i++) &#123; flag[i] = 0; // 顶点i的最短路径还没获取到。 prev[i] = 0; // 顶点i的前驱顶点为0。 dist[i] = G.matrix[vs][i];// 顶点i的最短路径为&quot;顶点vs&quot;到&quot;顶点i&quot;的权。 &#125; // 对&quot;顶点vs&quot;自身进行初始化 flag[vs] = 1; dist[vs] = 0; // 遍历G.vexnum-1次；每次找出一个顶点的最短路径。 for (i = 1; i &lt; G.vexnum; i++) &#123; // 寻找当前最小的路径； // 即，在未获取最短路径的顶点中，找到离vs最近的顶点(k)。 min = INF; for (j = 0; j &lt; G.vexnum; j++) &#123; if (flag[j]==0 &amp;&amp; dist[j]&lt;min) &#123; min = dist[j]; k = j; &#125; &#125; // 标记&quot;顶点k&quot;为已经获取到最短路径 flag[k] = 1; // 修正当前最短路径和前驱顶点 // 即，当已经&quot;顶点k的最短路径&quot;之后，更新&quot;未获取最短路径的顶点的最短路径和前驱顶点&quot;。 for (j = 0; j &lt; G.vexnum; j++) &#123; tmp = (G.matrix[k][j]==INF ? INF : (min + G.matrix[k][j])); // 防止溢出 if (flag[j] == 0 &amp;&amp; (tmp &lt; dist[j]) ) &#123; dist[j] = tmp; prev[j] = k; &#125; &#125; &#125; // 打印dijkstra最短路径的结果 printf(&quot;dijkstra(%c): \n&quot;, G.vexs[vs]); for (i = 0; i &lt; G.vexnum; i++) printf(&quot; shortest(%c, %c)=%d\n&quot;, G.vexs[vs], G.vexs[i], dist[i]);&#125; 迪杰斯特拉算法时间复杂度分析由算法代码可知，本算法主要部分为一个双重循环，外层循环内部有两个并列的单层循环，可以任取一个循环内的操作为基本操作，基本操作执行的总次数为$n^2$ 因此时间复杂度为$O(n^2)$. 弗洛伊德（Floyd）算法弗洛伊德算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或有向图或负权（但不可存在负权回路)的最短路径问题，同时也被用于计算有向图的传递闭包。 弗洛伊德算法思想通过Floyd计算图G=(V,E)中各个顶点的最短路径时，需要引入两个矩阵，矩阵S中的元素a[i][j]表示顶点i(第i个顶点)到顶点j(第j个顶点)的距离。矩阵P中的元素b[i][j]，表示顶点i到顶点j经过了b[i][j]记录的值所表示的顶点。 假设图G中顶点个数为N，则需要对矩阵D和矩阵P进行N次更新。初始时，矩阵D中顶点a[i][j]的距离为顶点i到顶点j的权值；如果i和j不相邻，则a[i][j]=∞，矩阵P的值为顶点b[i][j]的j的值。 接下来开始，对矩阵D进行N次更新。第1次更新时，如果”a[i][j]的距离” &gt; “a[i][0]+a[0][j]”(a[i][0]+a[0][j]表示”i与j之间经过第1个顶点的距离”)，则更新a[i][j]为”a[i][0]+a[0][j]”,更新b[i][j]=b[i][0]。 同理，第k次更新时，如果”a[i][j]的距离” &gt; “a[i][k-1]+a[k-1][j]”，则更新a[i][j]为”a[i][k-1]+a[k-1][j]”,b[i][j]=b[i][k-1]。更新N次之后，操作完成！ 弗洛伊德算法过程1）设置两个矩阵A 和PATH，初始时将图的邻接矩阵赋值给A，将矩阵Path中元素全部设置为01.2）以顶点K为中间顶点，k取0~n-1(n为图中顶点个数)，对图中所有顶点对{i，j}进行如下检测：如果A[i][j]&gt;A[i][k]+A[k][j]，则将A[i][j]改成A[i][k]+A[k][j]的值，将Path[i][j]改成K，否则什么也不做 弗洛伊德算法代码12345678910111213141516171819void Floyd(MGraph g,int Paht[][maxSize])&#123; int i,j,k; int A[maxSize][maxSize]; //这个双循环对数组A和Path进行了初始化 for(i=0;i&lt;g.n;++i)&#123; A[i][j]=g.edges[i][j]; Path[i][j]=-1; &#125; for (int k = 0; k &lt; g.n; ++k) &#123; for (int i = 0; i &lt; g.n; ++i) &#123; for (int j = 0; j &lt; g.n; ++j) &#123; if(A[i][j]&gt;A[i][k]+A[k][j])&#123; A[j][j] = A[i][k]+A[k][j]; Paht[i][j]=k; &#125; &#125; &#125; &#125;&#125; 弗洛伊德算法时间复杂度分析由算法可知，主要是有三层循环，基本操作执行次数为$n^3$，所以时间复杂度为$O(n^3)$ 拓扑排序AOV网活动在顶点上的网（Activity On Vertex network,AOV）是一种可以形象的反映出整个工程中各个活动之间的先后关系的有向图。 拓扑排序介绍拓扑排序(Topological Order)是指，将一个有向无环图(Directed Acyclic Graph简称DAG)进行排序进而得到一个有序的线性序列。这样说，可能理解起来比较抽象。下面通过简单的例子进行说明！例如，一个项目包括A、B、C、D四个子部分来完成，并且A依赖于B和D，C依赖于D。现在要制定一个计划，写出A、B、C、D的执行顺序。这时，就可以利用到拓扑排序，它就是用来确定事物发生的顺序的。在拓扑排序中，如果存在一条从顶点A到顶点B的路径，那么在排序结果中B出现在A的后面。 拓扑排序算法思路 构造一个队列Q(queue) 和 拓扑排序的结果队列T(topological)； 把所有没有依赖顶点的节点放入Q； 当Q还有顶点的时候，执行下面步骤：3.1 从Q中取出一个顶点n(将n从Q中删掉)，并放入T(将n加入到结果集中)；3.2 对n每一个邻接点m(n是起点，m是终点)；3.2.1 去掉边&lt;n,m&gt;;3.2.2 如果m没有依赖顶点，则把m放入Q;注：顶点A没有依赖顶点，是指不存在以A为终点的边。以上图为例，来对拓扑排序进行演示 第1步：将B和C加入到排序结果中。 顶点B和顶点C都是没有依赖顶点，因此将C和C加入到结果集T中。假设ABCDEFG按顺序存储，因此先访问B，再访问C。访问B之后，去掉边&lt;B,A&gt;和&lt;B,D&gt;，并将A和D加入到队列Q中。同样的，去掉边&lt;C,F&gt;和&lt;C,G&gt;，并将F和G加入到Q中。 (01) 将B加入到排序结果中，然后去掉边&lt;B,A&gt;和&lt;B,D&gt;；此时，由于A和D没有依赖顶点，因此并将A和D加入到队列Q中。 (02) 将C加入到排序结果中，然后去掉边&lt;C,F&gt;和&lt;C,G&gt;；此时，由于F有依赖顶点D，G有依赖顶点A，因此不对F和G进行处理。第2步：将A,D依次加入到排序结果中。 第1步访问之后，A,D都是没有依赖顶点的，根据存储顺序，先访问A，然后访问D。访问之后，删除顶点A和顶点D的出边。第3步：将E,F,G依次加入到排序结果中。 因此访问顺序是：B -&gt; C -&gt; A -&gt; D -&gt; E -&gt; F -&gt; G 第二部分 计算机系统基础考试题型：问答、分析、编程 总分：40分 一 、处理器体系结构内容：CPU中的时序电路、单周期处理器的设计、流水线处理器的基本原理、Data Hazard的处理、流水线设计中的其他问题 二、优化程序性能内容：优化程序性能、优化编译器的能力和局限性以及表示程序性能、特定体系结构或应用特性的性能优化、限制因素、确认和消除性能瓶颈 三、存储器结构及虚拟存储器内容：局部性、存储器层级结构、计算机高速缓存器原理、高速缓存对性能的影响、地址空间、虚拟存储器、虚拟内存的管理、翻译和映射、TLB、动态存储器分配和垃圾收集 四、链接、进程及并发编程内容：静态链接、目标文件、符号和符号表、重定位和加载、动态链接库、异常和进程、进程控制和信号、进程间的通信、进程间信号量的控制、信号量，各种并发编程模式，共享变量和线程同步，其他并行问题 五、系统级I/O和网络编程内容：I/O相关概念、文件及文件操作、共享文件、网络编程、客户端-服务器模型，套接字接口、HTTP请求，Web服务器 第三部分 软件工程考试题型：概念问答题、实践案例题 总分：50分 一、软件过程软件过程的概念软件过程是指软件整个生命周期，从需求获取，需求分析，设计，实现，测试，发布和维护一个过程模型。一个软件过程定义了软件开发中采用的方法，但软件过程还包含该过程中应用的技术——技术方法和自动化工具。过程定义一个框架，为有效交付软件工程技术，这个框架必须创建。软件过程构成了软件项目管理控制的基础，并且创建了一个环境以便于技术方法的采用、工作产品（模型、文档、报告、表格等）的产生、里程碑的创建、质量的保证、正常变更的正确管理。 经典软件过程模型的特点（瀑布模型、增量模型、演化模型、统一过程模型）瀑布模型（Waterfall Model） 1970年Winston Royce提出了著名的”瀑布模型”，直到80年代早期，它一直是唯一被广泛采用的软件开发模型。 瀑布模型将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如同瀑布流水，逐级下落。 在瀑布模型中，软件开发的各项活动严格按照线性方式进行，当前活动接受上一项活动的工作结果，实施完成所需的工作内容。当前活动的工作结果需要进行验证，如果验证通过，则该结果作为下一项活动的输入，继续进行下一项活动，否则返回修改。 瀑布模型强调文档的作用，并要求每个阶段都要仔细验证。但是，这种模型的线性过程太理想化，已不再适合现代的软件开发模式，几乎被业界抛弃，其主要问题在于： （1） 各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量； （2） 由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发的风险； （3） 早期的错误可能要等到开发后期的测试阶段才能发现，进而带来严重的后果。 我们应该认识到，”线性”是人们最容易掌握并能熟练应用的思想方法。当人们碰到一个复杂的”非线性”问题时，总是千方百计地将其分解或转化为一系列简单的线性问题，然后逐个解决。一个软件系统的整体可能是复杂的，而单个子程序总是简单的，可以用线性的方式来实现，否则干活就太累了。线性是一种简洁，简洁就是美。当我们领会了线性的精神，就不要再呆板地套用线性模型的外表，而应该用活它。例如增量模型实质就是分段的线性模型，螺旋模型则是接连的弯曲了的线性模型，在其它模型中也能够找到线性模型的影子 增量模型（Incremental Model）与建造大厦相同，软件也是一步一步建造起来的。在增量模型中，软件被作为一系列的增量构件来设计、实现、集成和测试，每一个构件是由多种相互作用的模块所形成的提供特定功能的代码片段构成. 增量模型在各个阶段并不交付一个可运行的完整产品，而是交付满足客户需求的一个子集的可运行产品。整个产品被分解成若干个构件，开发人员逐个构件地交付产品，这样做的好处是软件开发可以较好地适应变化，客户可以不断地看到所开发的软件，从而降低开发风险。但是，增量模型也存在以下缺陷： （1） 由于各个构件是逐渐并入已有的软件体系结构中的，所以加入构件必须不破坏已构造好的系统部分，这需要软件具备开放式的体系结构。 （2） 在开发过程中，需求的变化是不可避免的。增量模型的灵活性可以使其适应这种变化的能力大大优于瀑布模型和快速原型模型，但也很容易退化为边做边改模型，从而是软件过程的控制失去整体性。 在使用增量模型时，第一个增量往往是实现基本需求的核心产品。核心产品交付用户使用后，经过评价形成下一个增量的开发计划，它包括对核心产品的修改和一些新功能的发布。这个过程在每个增量发布后不断重复，直到产生最终的完善产品。 演化模型增量模型与演化模型的相同点是：基本思想都是非整体开发，以渐增方式开发系统。他们的目的基本相同：使用户尽早得到部分软件这样能听取用户反馈。不同点：增量模型再需求设计阶段是整体进行的，在编码测试阶段是渐增进行的。演化模型全部系统是增量开发，增量提交。 统一过程模型统一过程模型是一种以“用例和风险驱动、以体系结构为核心、迭代及增量”为特征的软件过程框架，一般由UML方法和工具支持。用例是捕获需求的方法，因此，也可以说UP是需求驱动的。UP的另一个驱动就是风险，因为如果你不主动预测和防范风险，风险就会主动攻击你。UP需要对软件开发中的风险进行分析、预测并关注软件的构造。在基于组件的开发总，体系结构描述了系统的整体框架：如何把系统划分成组件以及这些组件如何进行交互和部署在硬件上。UP方法实际上就是开发和演进一个健壮的系统体系结构。此外，UP也是迭代和增量的。在UP的迭代构建中，每个迭代包括五个核心工作流：需求R-捕捉系统应该做什么。分析A-精华和结构化需求。设计D-基于系统结构来实现需求。实现I-构造软件系统。测试T-验证实现是否达到预期效果。 尽管每次迭代都可以包含这5个核心工作流，但是特定工作流的重点依赖于项目生命周期中的迭代发生的位置。迭代的一些可能工作流图解如图2-8所示。把项目划分成一系列迭代，允许对项目进行灵活计划。最简单的方法是按照时间顺序的迭代序列，一个接一个。然而，常常可能并行安排迭代。这意味着需要理解每次迭代的制品之间的依赖，需要有方法指导基于框架和模型的并行迭代。并行迭代的好处是缩短面市时间，可以更好地利用团队，但是必须仔细计划。 过程评估与CMM/CMMI的基本概念过程评估 软件过程评估所关注的是软件组织自身内部软件过程的改进问题，目的在于发现缺陷，提出改进的方向。 CMM的概念CMM(Capability Maturity Model)是能力成熟度模型的缩写,CMM是国际公认的对软件公司进行成熟度等级认证的重要标准。CMM共分五级。在每一级中，定义了达到该级过程管理水平所应解决的关键问题和关键过程。每一较低级别是达到较高级别的基础。其中五级是最高级，即优化级，达到该级的软件公司过程可自发地不断改进，防止同类问题二次出现；四级称为已管理级，达到该级的软件公司已实现过程的定量化；三级为已定义级，即过程实现标准化；二级为可重复级，达到该级的软件公司过程已制度化，有纪律，可重复；一级为初始级，过程无序，进度、预算、功能和质量等方面不可预测。 CMMI的概念（Capability Maturity Model Integration，能力成熟度模型集成）将各种能力成熟度模型，即：Software CMM、Systems Eng-CMM、People CMM和Acquisition CMM，整合到同一架构中去，由此建立起包括软件工程、系统工程和软件采购等在内的诸模型的集成，以解决除软件开发以外的软件系统工程和软件采购工作中的迫切需求。CMMI的基本思想1、解决软件项目过程改进难度增大问题2、实现软件工程的并行与多学科组合3、实现过程改进的最佳效益 敏捷宣言与敏捷过程的特点敏捷宣言也叫做敏捷软件开发宣言，正式宣布了对四种核心价值和十二条原则，可以指导迭代的以人为中心的软件开发方法。敏捷宣言强调的敏捷软件开发的四个核心价值是：个体和互动高于流程和工具工作的软件高于详尽的文档客户合作高于合同谈判响应变化高于遵循计划 敏捷过程的特点与传统开发方法相比，在敏捷开发的整个过程中，有以下几个主要的特点：（1）敏捷开发的过程有着更强的适应性而不是预设性，从敏捷宣言的第四条响应变化高于预设计划便可以看出来。因为软件开发过程的本身的不可预见性，很多用户在项目开始时不可能对于这个项目有着一个完整而明确的预期。很多对软件的预期都在后期的修改和完善过程中产生。因此高适应性显然更加符合软件工程开发的实际。而敏捷开发实现其适应性的方式主要在于，第一，缩短把项目提交给用户的周期；第二，增加用户，业务人员，开发人员这三者之间的交流；第三，通过减少重构的成本以增加软件的适应性。（2）敏捷开发的过程中，更加的注重人的因素。在传统软件工程中，个人的因素很少的被考虑到分工中，每个个体都是只是整个代码开发机器的一个小小的螺丝钉，个人的意志和创造力很大程度上的被抹去为了更好的为集体服务。而在敏捷开发过程中，每个个人的潜力被充分的考虑，应用什么技术很大程度上直接由在第一线开发的技术人员决定；每个人的特点和创造力都可以充分地发挥，这样开发出来的软件更加的具有生命力，因为他融入了开发者的心血和创意，开发者不再是进行机械的乏味的堆砌，而是创造属于自己的艺术品，这样的条件下产生的代码必然在质量上更占优势。（3）在敏捷开发的过程中，整个项目是测试驱动的而不是文档驱动的。不仅每个模块有着自己的相应的测试单元，开发人员在开发自己的模块的过程中必须保证自己所开发的模块可以通过这一单元的测试，并且集成测试贯穿了整个开发过程的始终。集成测试每天会进行十几次甚至几十次，而不是像传统方法一样只有当各个模块的编码都结束了之后再进行联合调试。这样，在软件开发的进程中每一点改动所引起的问题都容嘉容易暴露出来，使得更加容易在错误刚刚产生的时候发现问题从而解决问题。这样就避免了在最后整个系统完成时错误隐藏的太深给调试造成极大的困难。 二、软件需求软件需求的概念软件需求是(1)用户解决问题或达到目标所需条件或权能(Capability)。 (2)系统或系统部件要满足合同、标准、规范或其它正式规定文档所需具有的条件或权能。 (3)一种反映上面(1)或(2)所述条件或权能的文档说明。它包括功能性需求及非功能性需求，非功能性需求对设计和实现提出了限制，比如性能要求，质量标准，或者设计限制。 软件需求包括三个不同的层次—业务需求、用户需求和功能需求—也包括非功能需求。 业务需求( business requirement)反映了组织机构或客户对系统、产品高层次的目标要求，它们在项目视图与范围文档中予以说明。 用户需求(user requirement)文档描述了用户使用产品必须要完成的任务，这在使用实例(use case)文档或方案脚本(scenario)说明中予以说明。 功能需求(functional requirement)定义了开发人员必须实现的软件功能，使得用户能完成他们的任务，从而满足了业务需求。所谓特性(feature)是指逻辑上相关的功能需求的集合，给用户提供处理能力并满足业务需求。软件需求各组成部分之间的关系如图所示。 非功能需求作为补充，软件需求规格说明还应包括非功能需求，它描述了系统展现给用户的行为和执行的操作等。它包括产品必须遵从的标准、规范和合约；外部界面的具体细节；性能要求；设计或实现的约束条件及质量属性。所谓约束是指对开发人员在软件产品设计和构造上的限制。质量属性是通过多种角度对产品的特点进行描述，从而反映产品功能。多角度描述产品对用户和开发人员都极为重要。 值得注意的一点是，需求并未包括设计细节、实现细节、项目计划信息或测试信息。需求与这些没有关系，它关注的是充分说明你究竟想开发什么。 需求工程的基本过程需求工程的活动划分为以下5个独立的阶段：需求获取：通过与用户的交流，对现有系统的观察及对任务进行分析，从而开发、捕获和修订用户的需求；需求建模：为最终用户所看到的系统建立一个概念模型，作为对需求的抽象描述，并尽可能多的捕获现实世界的语义；形成需求规格：生成需求模型构件的精确的形式化的描述，作为用户和开发者之间的一个协约；需求验证：以需求规格说明为输入，通过符号执行、模拟或快速原型等途径，分析需求规格的正确性和可行性，包含有效性检查，一致性检查，可行性检查和确认可验证性；需求管理：支持系统的需求演进，如需求变化和可跟踪性问题。 需求获取阶段需求获取首先需要的是技术的支持，其次，在需求获取工作中主要涉及了 3 个至关重要的因素：应搜集什么信息；从什么来源中搜集信息；用什么机制或技术搜集信息。再次，需求获取的开始，代表着软件项目正式开始实施，正所谓万事开头难。综合上述 3 个点使得需求获取成为软件开发中最困难、最关键、最易出错也是最需要交流的方面。在工作开展中，主要是就业务流程、组织架构、软硬件环境和现有系统等相关内容进行沟通，挖掘系统最终用户的真正需求，把握需求的方向。在需求获取调研会中首先对需求获取方法作了验证。现行的需求获 取方法一般有基于调查的需求获取方法、基于用例的需求获取方法、原型法等几种方法。各种需求获取方法各有利弊。[7] 需求分析阶段需求分析与需求获取是密切相关的，需求获取是需求分析的基础，需求分析是需求获取的直接表现，两者相互促进，相互制约。需求分析与需求获取的不同主要在于需求分析是在已经了解承建方的实际的客观的较全面的业务及相关信息的基础上，结合软、硬件实现方案，并做出初步的系统原型给承建方做演示。承建方则通过原型演示来体验业务流程的合理化、准确性、易用性。同时，用户还要通过原型演示及时地发现并提出其中存在的问题和改进意见和方法。 需求文档编写阶段需求开发的最终成果是，在对所要开发的产品达成共识后，所编写的具体的文档。需求文档是在需求获取和需求分析两个阶段任务结束时生成的，所以文档要包含所有需求。在此阶段先要从软件工程和文档管理的角度出发依据相关的标准审核需求文档内容，确定需求文档内容是否完整。对需求文档中存留问题进行修改的工作。 需求确认阶段需求确认主要是针对《需求规格说明书》的评审，保证需求符合优秀需求成熟的特征，并且符合好的需求规格说明的特征。在需求确认阶段需要保证以下几点： （1）软件需求规格说明正确描述了预期的满足各方涉众需求的系统能力和特征。 （2）从系统需求、业务规则或其他来源中正确的推导出软件需求。 （3）需求是完整的、高质量的。 （4）需求的表示在所有地方都是一致的。 （5）需求为继续进行产品设计和构造提供充分的基础。 需求跟踪阶段与需求复用阶段需求跟踪是指通过比较需求文档与后续工作成果之间的对应关系，确保产品依据需求文档进行开发，建立与维护“需求——设计——编程——测试”之间的一致性，确保所有工作成果符合用户需求。需求跟踪是一项需要进行大量手工劳动的任务，在系统开发和维护的过程中一定要随时对跟踪联系链信息进行更新。需求跟踪能力的好坏会直接影响产品质量，降低维护成本，容易实现复用，同时，需求跟踪还需要建设方的大力支持。 需求复用阶段在软件项目实施过程中，许多不同项目间存在着许多相似的需求，尤其是类型相同的项目在不同的用户群众的实施中，需求的相似性就更加明显、更加普遍了。有了需求复用，建设方就能快速的形成一个需求的原型，这样，后期的需求工作只需要在此原型的基础上进行修改、扩充和完善即可，大大提高了需求分析的工作进度。所以，对于需求的复用就需要加以重视。对于需求复用，首要责任就是要提取可复用的需求，对需求复用的理解和扩充。其次就是要保证需求复用不存在冲突。 需求变更控制阶段需求变更在软件项目开发中是不可避免的。无休止的需求变更只会造成各种资源无休止的浪费，但是其中也不乏有许多是必要的、合理的需求变更。对于需求变更，首先是要尽量及早的发现，以避免更大的损失。其次，是要采取相应的、合理的变更管理制度和流程，这样同样可以降低需求变更带来的风险。 版本控制阶段版本控制是管理需求规格说明和其他项目文档必不可少的一个方面，也是需求变更文档化管理的最有效办法。可以详细记录发生需求变更的需求文档版本的版本，发生变更的原因，变更发生的控制记录，并对变更后的需求文档进行唯一版本号的标识。使得每个成员都能及时访问最新版本的需求文档。实施版本控制的基础是需求基线，所谓需求基线就是项目组成员一经承诺将在某一特定产品版本中实现的功能性和非功能性需求的集合。需求基线的确定可以保证项目的涉众各方可以对发布的产品中希望具有的功能和属性有一个一致的理解。 分层数据流模型用例和场景建模及其UML表达（用例图、活动图、泳道图、顺序图）数据模型建模及其UML表达（类图）行为模型建模及其UML表达（状态机图）。三、软件设计与构造软件体系结构及体系结构风格的概念；设计模式的概念；模块化设计的基本思想及概念（抽象、分解、模块化、封装、信息隐藏、功能独立）；软件重构的概念；软件体系结构的UML建模（包图、类图、构件图、顺序图、部署图）；接口的概念；面向对象设计原则（开闭原则、Liskov替换原则、依赖转置原则、接口隔离原则）；内聚与耦合的概念、常见的内聚和耦合类型。 四、软件测试软件测试及测试用例的概念；单元测试、集成测试、确认测试、系统测试、回归测试的概念；调试的概念、调试与测试的关系；测试覆盖度的概念；白盒测试、黑盒测试的概念；代码圈复杂度的计算方法；白盒测试中的基本路径测试方法；黑盒测试中的等价类划分方法。]]></content>
      <categories>
        <category>复习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[详解神经网络]]></title>
    <url>%2F2018%2F07%2F20%2Fcjk9hluxb0001qufupvaljvhc%2F</url>
    <content type="text"><![CDATA[详解神经网络神经网络的结构神经网络由三部分组成，分别是最左边的输入层，隐藏层（实际应用中远远不止一层）和最右边的输出层。层与层之间用线连接在一起，每条连接线都有一个对应的权重值 w，除了输入层，一般来说每个神经元还有对应的偏置 b。 除了输入层的神经元，每个神经元都会有加权求和得到的输入值 z 和将 z 通过 Sigmoid 函数（也即是激活函数）非线性转化后的输出值 a，他们之间的计算公式如下其中，公式里面的变量l和j表示的是第 l 层的第 j 个神经元，ij 则表示从第 i 个神经元到第 j 个神经元之间的连线，w 表示的是权重，b 表示的是偏置，后面这些符号的含义大体上与这里描述的相似，所以不会再说明。下面的 Gif 动图可以更加清楚每个神经元输入输出值的计算方式（注意，这里的动图并没有加上偏置，但使用中都会加上）使用激活函数的原因是因为线性模型（无法处理线性不可分的情况）的表达能力不够，所以这里通常需要加入 Sigmoid 函数来加入非线性因素得到神经元的输出值。 可以看到 Sigmoid 函数的值域为 (0,1) ，若对于多分类任务，输出层的每个神经元可以表示是该分类的概率。当然还存在其他的激活函数，他们的用途和优缺点也都各异。 BP 算法执行的流程（前向传递和逆向更新）在手工设定了神经网络的层数，每层的神经元的个数，学习率 η（下面会提到）后，BP 算法会先随机初始化每条连接线权重和偏置，然后对于训练集中的每个输入 x 和输出 y，BP 算法都会先执行前向传输得到预测值，然后根据真实值与预测值之间的误差执行逆向反馈更新神经网络中每条连接线的权重和每层的偏好。在没有到达停止条件的情况下重复上述过程。 其中，停止条件可以是下面这三条 权重的更新低于某个阈值的时候 预测的错误率低于某个阈值 达到预设一定的迭代次数 譬如说，手写数字识别中，一张手写数字1的图片储存了28*28 = 784个像素点，每个像素点储存着灰度值(值域为[0,255])，那么就意味着有784个神经元作为输入层，而输出层有10个神经元代表数字0~9，每个神经元取值为0~1，代表着这张图片是这个数字的概率。 每输入一张图片（也就是实例），神经网络会执行前向传输一层一层的计算到输出层神经元的值，根据哪个输出神经元的值最大来预测输入图片所代表的手写数字。 然后根据输出神经元的值，计算出预测值与真实值之间的误差，再逆向反馈更新神经网络中每条连接线的权重和每个神经元的偏好。 前向传输（Feed-Forward） 从输入层=&gt;隐藏层=&gt;输出层，一层一层的计算所有神经元输出值的过程。 逆向反馈（Back Propagation） 因为输出层的值与真实的值会存在误差，我们可以用均方误差来衡量预测值和真实值之间的误差。 均方误差 逆向反馈的目标就是让E函数的值尽可能的小，而每个神经元的输出值是由该点的连接线对应的权重值和该层对应的偏好所决定的，因此，要让误差函数达到最小，我们就要调整w和b值， 使得误差函数的值最小。 权重和偏置的更新公式对目标函数 E 求 w 和 b 的偏导可以得到 w 和 b 的更新量，下面拿求 w 偏导来做推导。其中 η 为学习率，取值通常为 0.1 ~ 0.3,可以理解为每次梯度所迈的步伐。注意到 w_hj 的值先影响到第 j 个输出层神经元的输入值a，再影响到输出值y，根据链式求导法则有： 使用链式法则展开对权重求偏导 根据神经元输出值 a 的定义有：对函数 z 求 w 的偏导 Sigmoid 求导数的式子如下，从式子中可以发现其在计算机中实现也是非常的方便： 所以 则权重 w 的更新量为： 类似可得 b 的更新量为：但这两个公式只能够更新输出层与前一层连接线的权重和输出层的偏置，原因是因为 δ 值依赖了真实值y这个变量，但是我们只知道输出层的真实值而不知道每层隐藏层的真实值，导致无法计算每层隐藏层的 δ 值，所以我们希望能够利用 l+1 层的 δ 值来计算 l 层的 δ 值，而恰恰通过一些列数学转换后可以做到，这也就是逆向反馈名字的由来，公式如下:从式子中我们可以看到，我们只需要知道下一层的权重和神经元输出层的值就可以计算出上一层的 δ 值，我们只要通过不断的利用上面这个式子就可以更新隐藏层的全部权重和偏置了。 在推导之前请先观察下面这张图：首先我们看到 l 层的第 i 个神经元与 l+1 层的所有神经元都有连接，那么我们可以将 δ 展开成如下的式子：也即是说我们可以将 E 看做是 l+1 层所有神经元输入值的 z 函数，而上面式子的 n 表示的是 l+1 层神经元的数量，再进行化简后就可以得到上面所说的式子。 卷积神经网络卷积神经网络采用了三种基本概念：局部感受野（local receptive fields），共享权重（shared weights），和混合（pooling）。让我们逐个看下： 局部感受野在之前看到的全连接层的网络中，输入被描绘成纵向排列的神经元。但在一个卷积网络中，把输入看作是一个2828的方形排列的神经元更有帮助，其值对应于我们用作输入的28 28 的像素光强度：和通常一样，我们把输入像素连接到一个隐藏神经元层。但是我们不会把每个输入像素连接到每个隐藏神经元。相反，我们只是把输入图像进行小的，局部区域的连接。 说的确切一点，第一个隐藏层中的每个神经元会连接到一个输入神经元的一个小区域，例如，一个5*5的区域，对应于25个输入像素。所以对于一个特定的隐藏神经元，我们可能有看起来像这样的连接：这个输入图像的区域被称为隐藏神经元的局部感受野。它是输入像素上的一个小窗口。 每个连接学习一个权重。而隐藏神经元同时也学习一个总的偏置。你可以把这个特定的隐藏神经元看作是在学习分析它的局部感受野。 我们然后在整个输入图像上交叉移动局部感受野。对于每个局部感受野，在第一个隐藏层中有一个不同的隐藏神经元。为了正确说明，让我们从左上角开始一个局部感受野： 然后我们往右一个像素（即一个神经元）移动局部感受野，连接到第二个隐藏神经元：如此重复，构建起第一个隐藏层。注意如果我们有一个2828的输入图像，5 5的局部感受野，那么隐藏层中就会有24 * 24个神经元。这是因为在抵达右边（或者底部）的输入图像之前，我们只能把局部感受野横向移动23个神经元（或者往下23个神经元）。 我显示的局部感受野每次移动一个像素。实际上，有时候会使用不同的跨距。例如，我可以往右（或下）移动2个像素的局部感受野，这种情况下我们使用了1个跨距。在这章里我们大部分时候会固定使用1的跨距，但是值得知道人们有时用不同的跨距试验2。 共享权重和偏置：我已经说过每个隐藏神经元具有一个偏置和连接到它的局部感受野的55权重。我没有提及的是我们打算24 24隐藏神经元中的每一个使用相同的权重和偏置。换句话说，对第j,k个隐藏神经元，输出为： 这意味着第一个隐藏层的所有神经元检测完全相同的特征，只是在输入图像的不同位置。要明白为什么是这个道理，把权重和偏置设想成隐藏神经元可以挑选的东西，例如，在一个特定的局部感受野的垂直边缘。这种能力在图像的其它位置也很可能是有用的。因此，在图像中应用相同的特征检测器是非常有用的。用稍微更抽象的术语，卷积网络能很好地适应图像的平移不变性：例如稍稍移动一幅猫的图像，它仍然是一幅猫的图像。 因为这个原因，我们有时候把从输入层到隐藏层的映射称为一个特征映射。我们把定义特征映射的权重称为共享权重。我们把以这种方式定义特征映射的偏置称为共享偏置。共享权重和偏置经常被称为一个卷积核或者滤波器。在文献中，人们有时以稍微不同的方式使用这些术语，对此我不打算去严格区分；稍后我们会看一些具体的例子。 目前我描述的网络结构只能检测一种局部特征的类型。为了完成图像识别我们需要超过一个的特征映射。所以一个完整的卷积层由几个不同的特征映射组成： 共享权重和偏置的一个很大的优点是，它大大减少了参与的卷积网络的参数 池化/采样层 除了刚刚描述的卷积层，卷积神经网络也包含池化层（pooling layers）。池化层通常紧接着在卷积层之后使用。它要做的是简化从卷积层输出的信息。 详细地说，一个池化层取得从卷积层输出的每一个特征映射6并且从它们准备一个凝缩的特征映射。例如，混合层的每个单元可能概括了前一层的一（比如）22 的区域。作为一个具体的例子，一个常见的混合的程序被称最大值混合（max-pooling）。在最大池化层中，一个pooling单元简单地输出其2 2输入区域的最大激活值，正如下图说明的： 注意既然从卷积层有24 24个神经元输出，池化后我们得到12 12个神经元。 正如上面提到的，卷积层通常包含超过一个特征映射。我们将最大值混合分别应用于每一个特征映射。所以如果有三个特征映射，组合在一起的卷积层和池化层层看起来像这样： 综合在一起： 我们现在可以把这些思想都放在一起来构建一个完整的卷积神经网络。它和我们刚看到的架构相似，但是有额外的一层 10个输出神经元，对应于个可能的 MNIST 数字（’0’，’1’，’2’等）：]]></content>
  </entry>
  <entry>
    <title><![CDATA[反向传播]]></title>
    <url>%2F2018%2F03%2F20%2Fcjk9hluyx0004qufuewq6k7e0%2F</url>
    <content type="text"><![CDATA[反向传播(backpropagation)是如何工作的反向传播算法最早于上世纪70年代被提出，但是直到1986年，由David Rumelhart, Geoffrey Hinton, 和Ronald Williams联合发表了一篇著名论文之后，人们才完全认识到这个算法的重要性。这篇论文介绍了几种神经网络，在这些网络的学习中，反向传播算法比之前提出的方法都要快。这使得以前用神经网络不可解的一些问题，现在可以通过神经网络来解决。今天，反向传播算法是神经网络学习过程中的关键（workhorse）所在。反向传播算法的核心是一个偏微分表达式，表示代价函数对网络中的权重（或者偏置）求偏导。这个式子告诉我们，当我们改变权重和偏置的时候，代价函数的值变化地有多快。尽管这个式子有点复杂，这个式子也是很漂亮的，它的每一个部分都有自然的，直觉上的解释。因此，反向传播不仅仅是一种快速的学习算法，它能够让我们详细深入地了解改变权重和偏置的值是如何改变整个网络的行为的。这是非常值得深入学习的。 关于代价函数的两个架设反向传播算法的目标是计算代价函数对神经网络中出现的所有权重和偏置的偏导数和 第一条假设是代价函数能够被写成的形式，其中是每个独立训练样本的代价函数。在代价函数为平方代价函数的情况下，一个训练样本的代价是。该假设对于本书中涉及到的其它所有代价函数都成立。我们需要上述假设的原因是，反向传播实际上是对单个训练数据计算偏导数和。然后通过对所有训练样本求平均值获得和。事实上，有了这个假设，我们可以认为训练样本是固定的，然后把代价去掉下标表示为。最终我们会重新把加回公式，但目前为了简便我们将它隐去。 第二条假设是它可以写成关于神经网络输出结果的函数：平方代价函数满足该要求，因为单一训练样本的二次代价可以表示为：这是一个关于输出激活值的函数。显然，该代价函数也依赖于期望的输出，所以你可能疑惑为什么我们不把代价视为关于的函数。记住，输入的训练样本是固定的，因此期望的输出也是固定的。需要注意，我们不能通过改变权值或偏置来修改它，换句话说，它不是神经网络所学习的东西。所以把视为只关于输出的函数是有道理的。在该函数中只是帮助定义函数的参数。 Hadamard积反向传播算法是以常见线性代数操作为基础——诸如向量加法，向量与矩阵乘法等运算。但其中一个操作相对不是那么常用。具体来讲，假设和是两个有相同维数的向量。那么我们用来表示两个向量的对应元素(elementwise)相乘。因此的元素。例如，这种对应元素相乘有时被称为Hadamard积（Hadamard product）或Schur积(Schur product)。我们将称它为Hadamard积。优秀的矩阵库通常会提供Hadamard积的快速实现，这在实现反向传播时将会有用。 反向传播背后的四个基本等式反向传播(backpropagation)能够帮助解释网络的权重和偏置的改变是如何改变代价函数的。归根结底，它的意思是指计算偏导数和。但是为了计算这些偏导数，我们首先介绍一个中间量，，我们管它叫做层的神经元的错误量(error)。反向传播会提供给我们一个用于计算错误量的流程，能够把和、关联起来。为了理解错误量是如何定义的，想象一下在我们的神经网络中有一个恶魔： 这个恶魔位于层的神经元。当神经元的输入进入时，这个恶魔扰乱神经元的操作。它给神经元的加权输入添加了一点改变，这就导致了神经元的输出变成了，而不是之前的。这个改变在后续的网络层中传播，最终使全部代价改变了。而今，这个恶魔变成了一个善良的恶魔，它试图帮助你改善代价，比如，它试图找到一个能够让代价变小。假设是一个很大的值（或者为正或者为负）。然后这个善良的恶魔可以通过选择一个和符号相反的使得代价降低。相比之下，如果接近于0，那么这个恶魔几乎不能通过扰乱加权输入改善多少代价。在一定范围内这个善良的恶魔就可以分辨出，这个神经元已经接近于最佳状态1。至此，有了一种启发式的感觉：可以用来衡量神经元里的错误量。 1.输出层中关于错误量的等式（计算最后一层神经网络产生的错误）：推导过程 这是一种非常自然的表达。右侧的第一项，就是用于测量输出激活代价改变有多快的函数。举个例子，如果并不太依赖于某个特别的输出神经元，那么就会很小，这是我们所期望的。右侧的第二项，用于测量处的激活函数改变有多快。你应该注意到(BP1)中的每一项都是容易计算的。特别的，当计算神经网络的行为时就计算了，而计算也仅仅是一小部分额外的开销。当然了，的确切形式依赖于代价函数的形式。然而，如果提供了代价函数，大家也应该知道计算也不会有什么困难。举个例子，如果我们使用平方代价函数，即，那么，这显然很容易计算。等式(BP1)是的分量形式。它是一个完美的表达式，但并不是我们想要的基于矩阵的形式，那种矩阵形式可以很好的用于反向传播。然而，我们可以很容易把等式重写成基于矩阵的形式，就像：其中，是一个向量，它是由组成的。你可以把看做现对于输出激活的的改变速率。很容易看出来等式(BP1)和(BP1a)是等价的，基于这个原因我们从现在开始将使用(BP1)交替地指代两个等式。举个例子，在使用平方代价函数的情况下我们有，所以完整的基于矩阵的(BP1)的形式变为：就像你所看到的，表达式里的每一项都拥有一个漂亮的向量形式，并且很容易使用一个库来计算，比如Numpy。 2.依据下一层错误量获取错误量的等式（由后往前，计算每一层神经网络产生的错误）： 其中，是层的权重矩阵的转置。这个等式看着有些复杂，但是每一项都有很好的解释。假设我们知道层的错误量。当我们使用转置权值矩阵的时候，我们可以凭借直觉认为将错误反向（backward）移动穿过网络，带给我们某种测量层输出的错误量方法。然后我们使用Hadamard乘积。这就是将错误量反向移动穿过层的激活函数，产生了层的加权输入的错误量。通过结合(BP2)和(BP1)我们可以计算网络中任意一层的错误量。我们开始使用(BP1)来计算，然后应用等式(BP2)来计算，然后再次应用等式(BP2)来计算，以此类推，反向通过网络中的所有路径。 3.网络的代价函数相对于偏置的改变速率的等式（计算偏置的梯度）： 也就是说，错误量完全等于改变速率。这是一个很好的消息，因为(BP1)和(BP2)已经告诉我们如何计算。我们把(BP3)重写成如下的简略形式：这可以理解成可以和偏置在相同的神经元中被估计。 4.网络的代价函数相对于权重的改变速率的等式（计算权重的梯度）：： 这个等式告诉我们如何依据和来计算偏导，而这两个量我们已经知道如何计算了。这个等式可以重写成如下含有少量下标的形式：可以这么理解，是神经元的激活量，输入到权重中，是神经元的错误量，从权重输出。观察这个权重，两个神经元通过这个权重连接起来，我们可以这样描画出来： 等式(32)的一个很好的结论是当激活量很小的时候，，梯度项也将会趋近于很小。在这种情况下，我们说权重学习得很慢，也就是说在梯度下降的时候并没有改变很多。换而言之，等式(BP4)的一个结果就是从低激活量神经元里输出的权重会学习缓慢。 反向传播算法反向传播等式为我们提供了一个计算代价函数梯度的方法。下面让我们明确地写出该算法： 输入 :计算输入层相应的激活函数值。 正向传播：对每个，计算和。 输出误差 ：计算向量。 将误差反向传播：对每个计算 输出：代价函数的梯度为和通过以上算法就能看出它为什么叫反向传播算法。我们从最后一层开始，反向计算错误向量。在神经网络中反向计算误差可能看起来比较奇怪。但如果回忆反向传播的证明过程，会发现反向传播的过程起因于代价函数是关于神经网络输出值的函数。为了了解代价函数是如何随着前面的权重和偏置改变的，我们必须不断重复应用链式法则，通过反向的计算得到有用的表达式。 为什么说反向传播算法很高效？为什么说反向传播算法很高效？要回答这个问题，让我们来考虑另一种计算梯度的方式。设想现在是神经网络研究的早期阶段，大概是在上世纪50年代或60年代左右，并且你是第一个想到使用梯度下降方法来进行训练的人！但是要实现这个想法，你需要一种计算代价函数梯度的方式。你回想了你目前关于演算的知识，决定试一下是否能用链式法则来计算梯度。但是琢磨了一会之后发现，代数计算看起来非常复杂，你也因此有些失落。所以你尝试着寻找另一种方法。你决定把代价单独当做权重的函数（我们一会再来讨论偏置）。将权重写作，并且要对某个权重计算。一个很明显的计算方式是使用近似：其中是一个大于零的小正数。换句话说，我们可以通过计算两个差距很小的wj的代价，然后利用等式(46)来估计。我们可以利用相同的思想来对偏置求偏导。这种方式看起来很不错。它的概念很简单，实现起来也很简单，只需要几行代码就可以。当然了，他看起来要比使用链式法则来计算梯度靠谱多了！然而遗憾的是，虽然这种方式看起来很美好，但当用代码实现之后就会发现，它实在是太慢了。要理解其中的原因的话，设想在我们的神经网络中有一百万个权重，对于每一个不同的权重，为了计算，我们需要计算。这意味着为了计算梯度，我们需要计算一百万次代价函数，进而对于每一个训练样例，都需要在神经网络中前向传播一百万次。我们同样需要计算，因此总计需要一百万零一次前向传播。反向传播的优点在于它仅利用一次前向传播就可以同时计算出所有的偏导，随后也仅需要一次反向传播。大致来说，反向传播算法所需要的总计算量与两次前向传播的计算量基本相等（这应当是合理的，但若要下定论的话则需要更加细致的分析。合理的原因在于前向传播时主要的计算量在于权重矩阵的乘法计算，而反向传播时主要的计算量在于权重矩阵转置的乘法。很明显，它们的计算量差不多）。这与基于等式(46)的方法所需要的一百万零一次前向传播相比，虽然反向传播看起来更复杂一些，但它确实更更更更更快。这种加速方式在1986年首次被人们所重视，极大地拓展了神经网络能够适用的范围，也导致了神经网络被大量的应用。当然了，反向传播算法也不是万能的。在80年代后期，人们终于触及到了性能瓶颈，在利用反向传播算法来训练深度神经网络（即具有很多隐含层的网络）时尤为明显。在本书后面的章节中我们将会看到现代计算机以及一些非常聪明的新想法是如何让反向传播能够用来训练深度神经网络的。 反向传播：整体描述正如我之前所阐述的，反向传播涉及了两个谜题。第一个谜题是，这个算法究竟在做什么？我们之前的描述是将错误量从输出层反向传播。但是，我们是否能够更加深入，对这些矩阵、向量的乘法背后作出更加符合直觉的解释？第二个谜题是，人们一开始是如何发现反向传播算法的？按照算法流程一步步走下来，或者证明算法的正确性，这是一回事。但这并不代表你能够理解问题的本质从而能够从头发现这个算法。是否有一条合理的思维路线使你能够发现反向传播算法？在本节中，我会对这两个谜题作出解释。为了更好地构建的反向传播算法在做什么的直觉，让我们假设我们对网络中的某个权重做出了一个小的改变量： 这个改变量会导致与其相关的神经元的输出激活值的改变： 以此类推，会引起下一层的所有激活值的改变： 这些改变会继续引起再下一层的改变、下下层…依次类推，直到最后一层，然后引起代价函数的改变： 代价函数的改变量与最初权重的改变量是有关的，关系是下面这个等式这表明了计算的一种可能方法是，计算上的一个小改变量经过正向传播，对引起了多大的改变量。如果我们能够通过小心翼翼的计算做到这点，那我们就可以计算出。让我们尝试来写一下计算过程。改变量对层的第个神经元的激活值带来了的改变量。它的大小是激活值改变量会引起下一层（第层）的所有激活值都改变。我们先关注其中的一个结点，， 它产生的改变量是：将等式(48)带入其中，得到：当然，改变量会继续造成下一层的激活值的改变。实际上，我们可以想象一条从到的路径，其中每一个结点的激活值的改变都会引起下一层的激活值的改变，最终引起输出层的代价的改变。如果这条路径是，那么最终的改变量是这样，我们使用了一系列的形式的项，对应了路径上的每一个结点，包括最终项。这就计算出了在神经网络的这条路径上，最初的改变量引起了多大的改变。当然，由的改变量影响代价改变的路径选择是很多的，我们现在只考虑了其中的一条路径。为了计算最终总共的改变量，很显然我们应该对所有可能的路径对其带来的改变量进行求和：其中，我们对每条路径中所有出现的神经元都进行求和。与等式(47)进行比较，我们得到：等式(53)看上去很复杂。不过，它在直觉上很容易理解。我们计算出了相对于网络中的一个权重的变化速率。这个等式告诉我们的是，每一条连接两个神经元的边都可以对应一个变化速率，这个变化速率的大小是后一个神经元对前一个神经元的偏导。连接第一个权重和第一个神经元的边对应的变化速率是。一条路径对应的变化速率恰好是路径上的变化速率的连乘。总变化速率是从起始权重到最终代价上的所有可能的路径的变化速率的总和。用图片来说明这个过程，对于一条路径来说： 目前为止我所阐述的是一种启发式的观点，当你困惑于神经网络中的权重时，可以通过这种观点来思考。下面我会给你一些简要的思路使你可以更进一步的完善这个观点。首先，你可以显式地计算出等式53中的每一项的偏导表达式。这很容易做到，只需要一点计算量就行。做完之后，你可以尝试将所有的求和通过矩阵的形式来表示。这个过程会有一点无聊，并且需要一些毅力，但是不会特别的困难。随后，你可以尝试尽可能的将表达式简化，最终你会发现你得到了反向传播算法！所以，你可以将反向传播算法看作是一种对所有路径上的所有变化率进行求和的方法。或者用另外一种方式来说，反向传播算法是一种很聪明的方法，当小扰动沿着网络传播、到达输出并影响代价的过程中，它能够记录其对相应权重（和偏置）的影响量。我的解释到此为止了。这可能有点复杂，并且需要仔细思考所有的细节。如果你乐于接受挑战，你可能会很享受这个过程。如果不是，我希望我的这些想法能够给你一些关于反向传播在做什么的启发。那关于其它的谜题呢——反向传播最初是如何被发现的？实际上，如果你一路看下来我的阐述，你能够找到关于反向传播算法的一种证明。不幸的是，完整的证明实际上比我在本章的描述更长更复杂。那这个相对更简单（但更玄虚）的证明是如何发现的呢？当你把试图把完整的证明中的所有细节写出来时，你会发现有一些很显然能够被简化的形式。你做完这些简化，会得到一个简短一些的证明。然后你又会发现一些可以简化的内容。当你重复几次这个过程之后，你会得到本章中的这个简短的证明，但是它有点晦涩，因为其中所有复杂的结构都被简化掉了！我希望你能够相信我，完整的证明与本章中简短的证明没有什么本质区别。我只是对证明过程做了很多简化的工作。 转自gitbook Neural Networks and Deep Learning 翻译https://www.gitbook.com/book/hit-scir/neural-networks-and-deep-learning-zh_cn/details]]></content>
  </entry>
</search>
