<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《961复旦大学软件工程专业基础综合》]]></title>
    <url>%2F2018%2F07%2F23%2F%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%A4%8D%E4%B9%A0%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[第一部分 数据结构与算法考试题型：问答、分析、编程 总分：60分 一、栈（Stack）、队列（Queue）和向量（Vector）内容: 单链表,双向链表,环形链表,带哨兵节点的链表; 栈的基本概念和性质,栈ADT及其顺序,链接实现;栈的应用;栈与递归; 队列的基本概念和性质,队列ADT及其顺序,链接实现;队列的应用; 向量基本概念和性质;向量ADT及其数组、链接实现; 二、树树的基本概念和术语树是一种非线性的数据结构他是若干结点（A,B,C…等都是结点）的集合，是由唯一的根A和若干颗互不相交的子树组成的。其中每一棵子树又是一棵树，也是由唯一的根结点和若干颗互不相交的子树组成的。由此可知，树的定义是递归的。 树的结点包含一个数据元素以及若干指向其子树的分支。结点拥有的子树数目称为结点的度。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点。除根结点之外，分支结点也称为内部结点。树的度是树内各结点的度的最大值。结点的子树的根称为该结点的孩子。相应地，该结点称为孩子的双亲。同一个双亲的孩子之间互称为兄弟（Sibling）。结点的祖先(Ancestor)是从根到该结点所经分支上的所有结点。结点的层次：结点的层次从根开始定义起，根为第一层，根的孩子为第二层。若某结点在第L层，则其子树的根就在第L+1层。其双亲在同一层的结点互为堂兄弟。树中结点的最大层次称为树的深度或高度(Depth)。如果将树中结点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。森林是m(m&gt;=0)棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。 二叉树的先序,中序,后序,层次序遍历;先序遍历操作过程如下如果二叉树为空树，则什么都不做，否则：1）访问根节点2）先序遍历左子树3）先序遍历右子树对应的算法描述如下 12345678void preorder(BTNode *p)&#123; if(p!=NULL)&#123; Visit(p); preorder(p-&gt;lchild); preorder(p-&gt;rchild); &#125;&#125; 中序遍历操作如下如果二叉树为空树，则什么都不做，否则：1）中序遍历左子树。2）访问根节点。3）中序遍历右子树。对应的算法描述如下 1234567void inorder(BTNode *p)&#123; if(p!=NULL)&#123; preorder(p-&gt;lchild); Visit(p); preorder(p-&gt;rchild); &#125;&#125; 后序遍历操作如下如果二叉树为空树，则什么都不做，否则：1）后序遍历左子树。2）后序遍历右子树。3）访问根节点。对应的算法描述如下 1234567void postorder(BTNode *p)&#123; if(p!=NULL)&#123; preorder(p-&gt;lchild); preorder(p-&gt;rchild); Visit(p); &#125;&#125; 层次遍历如图所示为二叉树的层次遍历，即按照箭头所示方向，按照1，2，3，4的层次顺序对二叉树中的各个结点访问。要进行层次遍历需要建立一个循环队列，先将二叉树头结点入队列，然后出队列，访问该结点，如果他有左子树，则将左子树的根节点入队，如果他有右子树，则将右子树的根节点入队，然后出队列，对出对结点访问，如此反复，直到队列为空为止。得到的算法如下 12345678910111213141516171819202122232425void level(BTNode *p) &#123; int front, rear; BTNode *que[maxSize]; front = rear = 0; BTNode *q; if (p != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = p; while (front != rear) &#123; front = (front + 1) maxSize; q = que[front]; Visit(q); if (q-&gt;lchild != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = q-&gt;lchild; &#125; if (q-&gt;rchild != NULL) &#123; rear = (rear + 1) % maxSize; que[rear] = q-&gt;rchild; &#125; &#125; &#125;&#125; 二叉树遍历算法的改进二叉树深度优先遍历算法的非递归实现先序遍历非递归算法出栈时判断是否有孩子，右孩子先入栈，左孩子后入栈，因为对左孩子的访问要先于右孩子中序遍历非递归算法入栈即考虑左孩子是否存在，存在则入，出栈考虑其右孩子是否存在，存在则入。后序遍历非递归算法非递归先序遍历算法中的对左右子树的遍历顺序交换就可以得到逆后序遍历序列，然后将逆后序遍历序列逆序就得到了后序遍历。因此我们需要两个栈 线索二叉树中序线索二叉树线索二叉树(引线二叉树) 的定义如下:一个二叉树通过如下的方法“穿起来”：所有原本为空的右(孩子)指针改为指向该节点在中序序列中的后继，所有原本为空的左(孩子)指针改为指向该节点的中序序列的前驱。线索二叉树能线性地遍历二叉树，从而比递归的 中序遍历更快。使用线索二叉树也能够方便的找到一个节点的父节点，这比显式地使用父亲节点指针或者栈效率更高。这在栈空间有限，或者无法使用存储父节点的栈时很有作用（对于通过深度优先搜索来查找父节点而言)。 考虑这样的例子：一个节点k有一个右孩子r，那么r的左指针可能是指向一个孩子节点，或是一个指回k的线索。如果r有左孩子，这个左孩子同样也应该有一个左孩子或是指回k的线索。对于所有的左孩子同理。因此沿着这些从r发出的左指针，我们最终会找到一个指回k的线索。这种特性是对称的：当q是p的左孩子时，我们可以沿着q的右孩子找到一个指回p的线索。传统的二叉树一般都是以链式存储的结构来表示。这样，二叉树中的每个节点都可以用链表中的一个链节点来存储，每个链节点就包含了若干个指针。但是，这种传统的链式存储结构只能表现出二叉树中节点之间的父子关系，而且不能利用空余的指针来直接得到某个节点的在特定的遍历顺序（先序，中序，后序）中的直接前驱和直接后继。通过分析传统的二叉树链式存储结构表示的二叉树中，存在大量的空闲指针。若能利用这些空指针域来存放指向该节点的直接前驱或是直接后继的指针，则可以进行某些更方便的运算。这些被重新利用起来的空指针就被称为线索，加上了这些线索的二叉树就是线索二叉树。 二叉树及其性质二叉树的定义1）每个结点最多只有2颗子树，即二叉树中节点的度只能为0，1，22）子树有左右顺序之分，不能颠倒。性质1非空二叉树上叶子结点数等于双分支结点数加1性质2二叉树的第i层上最多有2^i-1个结点性质3高度或深度为k的二叉树最多有2^k-1个结点。换句话说，满二叉树中前k层的结点个数为2^k-1性质4有n个结点的完全二叉树，对各结点从上到下，从左到右依次编号（编号范围1~n）则结点之间有如下的关系若i为某结点a的编号则：如果i≠1，则a双亲结点的编号为 ⌊i/2⌋.如果2i≤n，则a左孩子的编号为2i；如果2i&gt;n，则a无左孩子。如果2i+1≤n，则a右孩子的编号为2i+1；如果2i+1&gt;n，则a无右孩子。性质5函数Catalan():给定n个结点，能够构成h(n)中不同的二叉树 h(n)=Cn=C(2n,n)/(n+1)注：C(n,r)=n!/[r!(n-r)!]性质6具有n(n&gt;0)个结点的完全二叉树的高度为⌊⌋ 普通树与二叉树的转换树转换成二叉树树转换成二叉树的过程如下1）将同一结点的各孩子结点用线串起来2）将每个结点的分支从左到右除了第一个外，其余的都剪掉，整理即可得到 二叉树转换成树二叉树转换为树是树转换为二叉树的逆过程，其步骤是：1）若某结点的左孩子结点存在，将左孩子结点的右孩子结点、右孩子结点的右孩子结点……都作为该结点的孩子结点，将该结点与这些右孩子结点用线连接起来；2）删除原二叉树中所有结点与其右孩子结点的连线；3）整理（1）和（2）两步得到的树，使之结构层次分明。 森林转换成二叉树森林是由若干棵树组成，可以将森林中的每棵树的根结点看作是兄弟，由于每棵树都可以转换为二叉树，所以森林也可以转换为二叉树。 将森林转换为二叉树的步骤是：1）先把每棵树转换为二叉树；2）第一棵二叉树不动，从第二棵二叉树开始，依次把后一棵二叉树的根结点作为前一棵二叉树的根结点的右孩子结点，用线连接起来。当所有的二叉树连接起来后得到的二叉树就是由森林转换得到的二叉树。 二叉树转换成森林二叉树转换为森林比较简单，其步骤如下：1）先把每个结点与右孩子结点的连线删除，得到分离的二叉树；2）把分离后的每棵二叉树转换为树；3）整理第（2）步得到的树，使之规范，这样得到森林。 森林和树的遍历根据树与二叉树的转换关系以及二叉树的遍历定义可以推知，树的先序遍历与其转换的相应的二叉树的先序遍历的结果序列相同；树的后序遍历与其转换的二叉树的中序遍历的结果序列相同；树的层序遍历与其转换的二叉树的后序遍历的结果序列相同。由森林与二叉树的转换关系以及森林与二叉树的遍历定义可知，森林的先序遍历和中序遍历与所转换得到的二叉树的先序遍历和中序遍历的结果序列相同。 树的存储结构,标准形式顺序存储结构树的顺序存储结构最简单直观的是双亲存储结构，用一维数组即可实现。将所有结点存到一个数组中。每个结点都有一个数据域data和一个数值parent指示其双亲在数组中存放的位置。根结点由于没有父结点，parent用-1表示。int tree[maxSize] 链式存储结构1）孩子存储结构孩子存储结构实质上就是图的邻接表存储结构树就是一种特殊的图，把图中的多对多关系删减成一对多关系即可的得到树2）孩子兄弟存储结构树转换成二叉树的过程 完全树(complete tree)的数组形式存储树的应用二叉排序树和平衡二叉树与查找关系密切，因为放到查找一章讲解 Huffman树的定义与应用Huffman树相关的概念1）路径：是指在一棵树中，从一个节点到另一个节点之间的分支构成的通路，如从节点8到节点1的路径如下图所示：2）路径的长度：是指路径上的分支数目，在上图中，路径长度为2。3）树的路径长度：是指从根到每个结点的路径长度之和。4）带权路径长度：结点具有权值，从该结点到根之间的路径长度乘以结点的权值，就是该结点的带权路径长度。5）树的带权路径长度：是指树中所有叶子节点的带权路径之和。6 节点的权：指的是为树中的每一个节点赋予的一个非负的值，如上图中每一个节点中的值 有了如上的概念，对于Huffman树，其定义为：给定n权值作为n个叶子节点，构造一棵二叉树，若这棵二叉树的带权路径长度达到最小，则称这样的二叉树为最优二叉树，也称为Huffman树。 Huffman树的构建给定n个权值，用这n个权值来构建赫夫曼树的算法描述如下：1）将这n个权值分别看成只有根节点的n棵二叉树，将这些二叉树的集合记为F。2）从F中选出两颗根结点的权值最小的树，作为左右子树，构建一棵新的二叉树，新的二叉树的根结点的权值为左右子结点的权值之和。3）从F中删去a,b，加入新构建的树C4）重复2，3步，直到F中只剩下一棵树为止，这棵树就是赫夫曼树。 对于树中节点的结构为： 1234567struct huffman_node&#123; char c; int weight; char huffman_code[LEN]; huffman_node * left; huffman_node * right;&#125;; 对于Huffman树的构建过程为： 1234567891011121314151617181920212223242526272829303132333435363738394041int huffman_tree_create(huffman_node *&amp;root, map&lt;char, int&gt; &amp;word)&#123; char line[MAX_LINE]; vector&lt;huffman_node *&gt; huffman_tree_node; map&lt;char, int&gt;::iterator it_t; for (it_t = word.begin(); it_t != word.end(); it_t++)&#123; // 为每一个节点申请空间 huffman_node *node = (huffman_node *)malloc(sizeof(huffman_node)); node-&gt;c = it_t-&gt;first; node-&gt;weight = it_t-&gt;second; node-&gt;left = NULL; node-&gt;right = NULL; huffman_tree_node.push_back(node); &#125; // 开始从叶节点开始构建Huffman树 while (huffman_tree_node.size() &gt; 0)&#123; // 按照weight升序排序 sort(huffman_tree_node.begin(), huffman_tree_node.end(), sort_by_weight); // 取出前两个节点 if (huffman_tree_node.size() == 1)&#123;// 只有一个根结点 root = huffman_tree_node[0]; huffman_tree_node.erase(huffman_tree_node.begin()); &#125;else&#123; // 取出前两个 huffman_node *node_1 = huffman_tree_node[0]; huffman_node *node_2 = huffman_tree_node[1]; // 删除 huffman_tree_node.erase(huffman_tree_node.begin()); huffman_tree_node.erase(huffman_tree_node.begin()); // 生成新的节点 huffman_node *node = (huffman_node *)malloc(sizeof(huffman_node)); node-&gt;weight = node_1-&gt;weight + node_2-&gt;weight; (node_1-&gt;weight &lt; node_2-&gt;weight)?(node-&gt;left=node_1,node-&gt;right=node_2):(node-&gt;left=node_2,node-&gt;right=node_1); huffman_tree_node.push_back(node); &#125; &#125; return 0;&#125; Huffman树的特点1）权值越大的结点，距离根结点越近。2）树中没有度为1的结点，这类树又叫做正则（严格）二叉树。3）树的带权路径长度最短 Huffman编码常见的.zip压缩文件和.jpeg图片文件的底层技术都用到了赫夫曼编码。例如字符串S=AAABBACCCDEEA A B C D E 5次 2次 3次 1次 2次 以出现的次数为权值，构建一个赫夫曼树，对每个结点的左右分支进行编号，左0右1，从根到每个结点的路径的数字序列即为每个字符的编码，对A~E的赫夫曼编码规则 A B C D E 0 110 10 1110 1111 则H(S)=00011011001010101110111111110上述有赫夫曼树导出每个字符的编码，进而得到整个字符串的编码的过程称为赫夫曼编码。在前缀码中，任一字符的编码串都不是另一字符编码串的前缀，赫夫曼编码产生的是最短前缀码。 赫夫曼n叉树赫夫曼二叉树是赫夫曼n叉树的一种特例，当对于结点数目大于等于2的待处理序列，都可以构造赫夫曼二叉树，但却不一定能构建赫夫曼n叉树，但无法构建时。需要补上权值为0的结点让整个序列凑成可以构造赫夫曼n叉树的序列。 三、查找(search)查找的基本概念查找的定义：给定一个K值，在含有N个记录的表中找出关键字等于K的记录。若找到，则查找成功，返回该记录的信息或者该记录在表中的位置；否则查找失败，返回相关的指示记录。由于查找算法的基本操作是关键字的比较，并且关键字比较次数与待查找关键字有关（对于一个查找表来说，对其中不同的关键字查找，关键字比较的次数一般不同），因此通常把查找过程中对关键字的平均比较次数作为衡量一个算法优劣的标准，平均查找长度用ASL来表示。 对线性关系结构的查找顺序查找基本思路：从表的一端开始，顺序扫描线性表，一次将扫描到的关键字和给定的K值比较。顺序查找法对于顺序表和链表都是适用的，对于顺序表，可以通过数组下标递增来顺序扫描数组中的各个元素；对于链表，则可以通过表结点指针反复执行p=p-&gt;next来扫描表中的各个元素。时间复杂度为0(n) 二分查找 Hash查找法,常见的Hash函数(直接定址法,随机数法),hash冲突的概念, 解决冲突的方法(开散列方法/拉链法,闭散列方法/开址定址法),二次聚集现象; BST树定义,性质,ADT及其实现,BST树查找,插入,删除算法; 平衡树 (AVL) 的定义,性质,ADT及其实现,平衡树查找,插入算法,平衡因子的概念; 优先队列与堆,堆的定义,堆的生成,调整算法;范围查询; 四、排序内容: 排序基本概念;插入排序,希尔排序,选择排序,快速排序,合并排序,基数排序等排序算法基本思想,算法代码及基本的时间复杂度分析 五、图图的基本概念一个图(G)定义为一个偶对(V,E) ，记为G=(V,E) 。其中： V是顶点(Vertex)的非空有限集合，记为V(G)；E是无序集V&amp;V的一个子集，记为E(G) ，其元素是图的弧(Arc)。 1.图图由结点的有穷集合V和边的集合E组成，为了与树形结构进行区别，在图结构中常常将结点称为顶点，边是顶点的有序偶对。若两个顶点之间存在一条边，则表示这两个顶点具有相邻关系。 2.有向图和无向图有向图(Digraph)： 若图G的关系集合E(G)中，顶点偶对&lt;v,w&gt;的v和w之间是有序的，称图G是有向图。 无向图(Undigraph)： 若图G的关系集合E(G)中，顶点偶对&lt;v,w&gt;的v和w之间是无序的，称图G是无向图。 3.弧在有向图中，若 &lt;v,w&gt;(G) ，表示从顶点v到顶点w有一条弧。 其中：v称为弧尾(tail)或始点(initial node)，w称为弧头(head)或终点(terminal node) 。 4.顶点的度，入度和出度无向图中，顶点 v 的度是指和 v 相关联的边的数目有向图中，以顶点 v 为弧头的弧的数目称为顶点 v 的入度，以顶点 v 为弧尾的弧的数目称为顶点 v 的出度 5.有向完全图和无向完全图有向图中每两个顶点之间都有两条方向相反的边连接的图称为有向完全图。弧数为 n(n -1)（结点为 n）无向图中每一对不同顶点恰有一条边相连的图称为无向完全图。边数为n(n−1)2（结点数为 n） 6.路径和路径长度从顶点 v 经过一系列的边或弧到达顶点 w ，则称这一系列的边或弧为顶点v 到顶点 w 的路径。路径长度是指路径上边的数目。 7.简单路径序列中顶点不重复出现的路径称为简单路径 8.回路若一条路径中第一个顶点和最后一个顶点相同，则这条路径是一条回路 9.连通,连通图和连通分量在无向图中，如果从顶点 v 到顶点 w 有路径，则称顶点 v 和 顶点 w 是连通的。如果对于图中的任意两个顶点都是连同的，则称为连通图。无向图中的极大连通子图为其连通分量。 10.强连通图和强连通分量在有向图中，如果对每一对顶点 v 、w 从v 和 从w到v都有路径，则称该有向图是强连通图。有向图中的极大强连通子图称为有向图的强连通分量。 11.权和网图中每条边都可以附带一个数，这种与边相关的数称为权，权可以表示从一个顶点到另一个顶点的距离或者花费的代价。边上带权的图称为带权图。 图的储存结构邻接矩阵邻接矩阵是表示顶点之间相邻关系的矩阵，存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组（称为邻接矩阵）存储图中的边或弧的信息。 从上面可以看出，无向图的边数组是一个对称矩阵。所谓对称矩阵就是n阶矩阵的元满足aij = aji。即从矩阵的左上角到右下角的主对角线为轴，右上角的元和左下角相对应的元全都是相等的。矩阵中“1”的个数为图中总边数的两倍，矩阵图中第i行和第i列元素之和即为顶点i的度对于有向图，矩阵中“1”的个数即为图的边数，矩阵中第i行的元素之和即为顶点i的出度，第j列的元素之和即为顶点j的入度 有权有向图中，无边的话0变成，1变成权值 邻接表邻接矩阵是不错的一种图存储结构，但是，对于边数相对顶点较少的图，这种结构存在对存储空间的极大浪费。因此，找到一种数组与链表相结合的存储方法称为邻接表。邻接表的处理方法是这样的：（1）图中顶点用一个一维数组存储，当然，顶点也可以用单链表来存储，不过，数组可以较容易的读取顶点的信息，更加方便。（2）图中每个顶点vi的所有邻接点构成一个线性表，由于邻接点的个数不定，所以，用单链表存储，无向图称为顶点vi的边表，有向图则称为顶点vi作为弧尾的出边表。例如，下图就是一个无向图的邻接表的结构。 图的遍历邻接表;图的遍历,广度度优先遍历和深度优先遍历;最小生成树基本概念,Prim算法,Kruskal算法;最短路径问题,广度优先遍历算法,Dijkstra算法,Floyd算法;拓扑排序 第二部分 计算机系统基础考试题型：问答、分析、编程 总分：40分 一 、处理器体系结构内容：CPU中的时序电路、单周期处理器的设计、流水线处理器的基本原理、Data Hazard的处理、流水线设计中的其他问题 二、优化程序性能内容：优化程序性能、优化编译器的能力和局限性以及表示程序性能、特定体系结构或应用特性的性能优化、限制因素、确认和消除性能瓶颈 三、存储器结构及虚拟存储器内容：局部性、存储器层级结构、计算机高速缓存器原理、高速缓存对性能的影响、地址空间、虚拟存储器、虚拟内存的管理、翻译和映射、TLB、动态存储器分配和垃圾收集 四、链接、进程及并发编程内容：静态链接、目标文件、符号和符号表、重定位和加载、动态链接库、异常和进程、进程控制和信号、进程间的通信、进程间信号量的控制、信号量，各种并发编程模式，共享变量和线程同步，其他并行问题 五、系统级I/O和网络编程内容：I/O相关概念、文件及文件操作、共享文件、网络编程、客户端-服务器模型，套接字接口、HTTP请求，Web服务器 第三部分 软件工程考试题型：概念问答题、实践案例题 总分：50分 一、软件过程软件过程的概念软件过程是指软件整个生命周期，从需求获取，需求分析，设计，实现，测试，发布和维护一个过程模型。一个软件过程定义了软件开发中采用的方法，但软件过程还包含该过程中应用的技术——技术方法和自动化工具。过程定义一个框架，为有效交付软件工程技术，这个框架必须创建。软件过程构成了软件项目管理控制的基础，并且创建了一个环境以便于技术方法的采用、工作产品（模型、文档、报告、表格等）的产生、里程碑的创建、质量的保证、正常变更的正确管理。 经典软件过程模型的特点（瀑布模型、增量模型、演化模型、统一过程模型）瀑布模型（Waterfall Model） 1970年Winston Royce提出了著名的”瀑布模型”，直到80年代早期，它一直是唯一被广泛采用的软件开发模型。 瀑布模型将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如同瀑布流水，逐级下落。 在瀑布模型中，软件开发的各项活动严格按照线性方式进行，当前活动接受上一项活动的工作结果，实施完成所需的工作内容。当前活动的工作结果需要进行验证，如果验证通过，则该结果作为下一项活动的输入，继续进行下一项活动，否则返回修改。 瀑布模型强调文档的作用，并要求每个阶段都要仔细验证。但是，这种模型的线性过程太理想化，已不再适合现代的软件开发模式，几乎被业界抛弃，其主要问题在于： （1） 各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量； （2） 由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发的风险； （3） 早期的错误可能要等到开发后期的测试阶段才能发现，进而带来严重的后果。 我们应该认识到，”线性”是人们最容易掌握并能熟练应用的思想方法。当人们碰到一个复杂的”非线性”问题时，总是千方百计地将其分解或转化为一系列简单的线性问题，然后逐个解决。一个软件系统的整体可能是复杂的，而单个子程序总是简单的，可以用线性的方式来实现，否则干活就太累了。线性是一种简洁，简洁就是美。当我们领会了线性的精神，就不要再呆板地套用线性模型的外表，而应该用活它。例如增量模型实质就是分段的线性模型，螺旋模型则是接连的弯曲了的线性模型，在其它模型中也能够找到线性模型的影子 增量模型（Incremental Model）与建造大厦相同，软件也是一步一步建造起来的。在增量模型中，软件被作为一系列的增量构件来设计、实现、集成和测试，每一个构件是由多种相互作用的模块所形成的提供特定功能的代码片段构成. 增量模型在各个阶段并不交付一个可运行的完整产品，而是交付满足客户需求的一个子集的可运行产品。整个产品被分解成若干个构件，开发人员逐个构件地交付产品，这样做的好处是软件开发可以较好地适应变化，客户可以不断地看到所开发的软件，从而降低开发风险。但是，增量模型也存在以下缺陷： （1） 由于各个构件是逐渐并入已有的软件体系结构中的，所以加入构件必须不破坏已构造好的系统部分，这需要软件具备开放式的体系结构。 （2） 在开发过程中，需求的变化是不可避免的。增量模型的灵活性可以使其适应这种变化的能力大大优于瀑布模型和快速原型模型，但也很容易退化为边做边改模型，从而是软件过程的控制失去整体性。 在使用增量模型时，第一个增量往往是实现基本需求的核心产品。核心产品交付用户使用后，经过评价形成下一个增量的开发计划，它包括对核心产品的修改和一些新功能的发布。这个过程在每个增量发布后不断重复，直到产生最终的完善产品。 演化模型增量模型与演化模型的相同点是：基本思想都是非整体开发，以渐增方式开发系统。他们的目的基本相同：使用户尽早得到部分软件这样能听取用户反馈。不同点：增量模型再需求设计阶段是整体进行的，在编码测试阶段是渐增进行的。演化模型全部系统是增量开发，增量提交。 统一过程模型统一过程模型是一种以“用例和风险驱动、以体系结构为核心、迭代及增量”为特征的软件过程框架，一般由UML方法和工具支持。用例是捕获需求的方法，因此，也可以说UP是需求驱动的。UP的另一个驱动就是风险，因为如果你不主动预测和防范风险，风险就会主动攻击你。UP需要对软件开发中的风险进行分析、预测并关注软件的构造。在基于组件的开发总，体系结构描述了系统的整体框架：如何把系统划分成组件以及这些组件如何进行交互和部署在硬件上。UP方法实际上就是开发和演进一个健壮的系统体系结构。此外，UP也是迭代和增量的。在UP的迭代构建中，每个迭代包括五个核心工作流：需求R-捕捉系统应该做什么。分析A-精华和结构化需求。设计D-基于系统结构来实现需求。实现I-构造软件系统。测试T-验证实现是否达到预期效果。 尽管每次迭代都可以包含这5个核心工作流，但是特定工作流的重点依赖于项目生命周期中的迭代发生的位置。迭代的一些可能工作流图解如图2-8所示。把项目划分成一系列迭代，允许对项目进行灵活计划。最简单的方法是按照时间顺序的迭代序列，一个接一个。然而，常常可能并行安排迭代。这意味着需要理解每次迭代的制品之间的依赖，需要有方法指导基于框架和模型的并行迭代。并行迭代的好处是缩短面市时间，可以更好地利用团队，但是必须仔细计划。 过程评估与CMM/CMMI的基本概念过程评估 软件过程评估所关注的是软件组织自身内部软件过程的改进问题，目的在于发现缺陷，提出改进的方向。 CMM的概念CMM(Capability Maturity Model)是能力成熟度模型的缩写,CMM是国际公认的对软件公司进行成熟度等级认证的重要标准。CMM共分五级。在每一级中，定义了达到该级过程管理水平所应解决的关键问题和关键过程。每一较低级别是达到较高级别的基础。其中五级是最高级，即优化级，达到该级的软件公司过程可自发地不断改进，防止同类问题二次出现；四级称为已管理级，达到该级的软件公司已实现过程的定量化；三级为已定义级，即过程实现标准化；二级为可重复级，达到该级的软件公司过程已制度化，有纪律，可重复；一级为初始级，过程无序，进度、预算、功能和质量等方面不可预测。 CMMI的概念（Capability Maturity Model Integration，能力成熟度模型集成）将各种能力成熟度模型，即：Software CMM、Systems Eng-CMM、People CMM和Acquisition CMM，整合到同一架构中去，由此建立起包括软件工程、系统工程和软件采购等在内的诸模型的集成，以解决除软件开发以外的软件系统工程和软件采购工作中的迫切需求。CMMI的基本思想1、解决软件项目过程改进难度增大问题2、实现软件工程的并行与多学科组合3、实现过程改进的最佳效益 敏捷宣言与敏捷过程的特点敏捷宣言也叫做敏捷软件开发宣言，正式宣布了对四种核心价值和十二条原则，可以指导迭代的以人为中心的软件开发方法。敏捷宣言强调的敏捷软件开发的四个核心价值是：个体和互动高于流程和工具工作的软件高于详尽的文档客户合作高于合同谈判响应变化高于遵循计划 敏捷过程的特点与传统开发方法相比，在敏捷开发的整个过程中，有以下几个主要的特点：（1）敏捷开发的过程有着更强的适应性而不是预设性，从敏捷宣言的第四条响应变化高于预设计划便可以看出来。因为软件开发过程的本身的不可预见性，很多用户在项目开始时不可能对于这个项目有着一个完整而明确的预期。很多对软件的预期都在后期的修改和完善过程中产生。因此高适应性显然更加符合软件工程开发的实际。而敏捷开发实现其适应性的方式主要在于，第一，缩短把项目提交给用户的周期；第二，增加用户，业务人员，开发人员这三者之间的交流；第三，通过减少重构的成本以增加软件的适应性。（2）敏捷开发的过程中，更加的注重人的因素。在传统软件工程中，个人的因素很少的被考虑到分工中，每个个体都是只是整个代码开发机器的一个小小的螺丝钉，个人的意志和创造力很大程度上的被抹去为了更好的为集体服务。而在敏捷开发过程中，每个个人的潜力被充分的考虑，应用什么技术很大程度上直接由在第一线开发的技术人员决定；每个人的特点和创造力都可以充分地发挥，这样开发出来的软件更加的具有生命力，因为他融入了开发者的心血和创意，开发者不再是进行机械的乏味的堆砌，而是创造属于自己的艺术品，这样的条件下产生的代码必然在质量上更占优势。（3）在敏捷开发的过程中，整个项目是测试驱动的而不是文档驱动的。不仅每个模块有着自己的相应的测试单元，开发人员在开发自己的模块的过程中必须保证自己所开发的模块可以通过这一单元的测试，并且集成测试贯穿了整个开发过程的始终。集成测试每天会进行十几次甚至几十次，而不是像传统方法一样只有当各个模块的编码都结束了之后再进行联合调试。这样，在软件开发的进程中每一点改动所引起的问题都容嘉容易暴露出来，使得更加容易在错误刚刚产生的时候发现问题从而解决问题。这样就避免了在最后整个系统完成时错误隐藏的太深给调试造成极大的困难。 二、软件需求软件需求的概念软件需求是(1)用户解决问题或达到目标所需条件或权能(Capability)。 (2)系统或系统部件要满足合同、标准、规范或其它正式规定文档所需具有的条件或权能。 (3)一种反映上面(1)或(2)所述条件或权能的文档说明。它包括功能性需求及非功能性需求，非功能性需求对设计和实现提出了限制，比如性能要求，质量标准，或者设计限制。 软件需求包括三个不同的层次—业务需求、用户需求和功能需求—也包括非功能需求。 业务需求( business requirement)反映了组织机构或客户对系统、产品高层次的目标要求，它们在项目视图与范围文档中予以说明。 用户需求(user requirement)文档描述了用户使用产品必须要完成的任务，这在使用实例(use case)文档或方案脚本(scenario)说明中予以说明。 功能需求(functional requirement)定义了开发人员必须实现的软件功能，使得用户能完成他们的任务，从而满足了业务需求。所谓特性(feature)是指逻辑上相关的功能需求的集合，给用户提供处理能力并满足业务需求。软件需求各组成部分之间的关系如图所示。 非功能需求作为补充，软件需求规格说明还应包括非功能需求，它描述了系统展现给用户的行为和执行的操作等。它包括产品必须遵从的标准、规范和合约；外部界面的具体细节；性能要求；设计或实现的约束条件及质量属性。所谓约束是指对开发人员在软件产品设计和构造上的限制。质量属性是通过多种角度对产品的特点进行描述，从而反映产品功能。多角度描述产品对用户和开发人员都极为重要。 值得注意的一点是，需求并未包括设计细节、实现细节、项目计划信息或测试信息。需求与这些没有关系，它关注的是充分说明你究竟想开发什么。 需求工程的基本过程需求工程的活动划分为以下5个独立的阶段：需求获取：通过与用户的交流，对现有系统的观察及对任务进行分析，从而开发、捕获和修订用户的需求；需求建模：为最终用户所看到的系统建立一个概念模型，作为对需求的抽象描述，并尽可能多的捕获现实世界的语义；形成需求规格：生成需求模型构件的精确的形式化的描述，作为用户和开发者之间的一个协约；需求验证：以需求规格说明为输入，通过符号执行、模拟或快速原型等途径，分析需求规格的正确性和可行性，包含有效性检查，一致性检查，可行性检查和确认可验证性；需求管理：支持系统的需求演进，如需求变化和可跟踪性问题。 需求获取阶段需求获取首先需要的是技术的支持，其次，在需求获取工作中主要涉及了 3 个至关重要的因素：应搜集什么信息；从什么来源中搜集信息；用什么机制或技术搜集信息。再次，需求获取的开始，代表着软件项目正式开始实施，正所谓万事开头难。综合上述 3 个点使得需求获取成为软件开发中最困难、最关键、最易出错也是最需要交流的方面。在工作开展中，主要是就业务流程、组织架构、软硬件环境和现有系统等相关内容进行沟通，挖掘系统最终用户的真正需求，把握需求的方向。在需求获取调研会中首先对需求获取方法作了验证。现行的需求获 取方法一般有基于调查的需求获取方法、基于用例的需求获取方法、原型法等几种方法。各种需求获取方法各有利弊。[7] 需求分析阶段需求分析与需求获取是密切相关的，需求获取是需求分析的基础，需求分析是需求获取的直接表现，两者相互促进，相互制约。需求分析与需求获取的不同主要在于需求分析是在已经了解承建方的实际的客观的较全面的业务及相关信息的基础上，结合软、硬件实现方案，并做出初步的系统原型给承建方做演示。承建方则通过原型演示来体验业务流程的合理化、准确性、易用性。同时，用户还要通过原型演示及时地发现并提出其中存在的问题和改进意见和方法。 需求文档编写阶段需求开发的最终成果是，在对所要开发的产品达成共识后，所编写的具体的文档。需求文档是在需求获取和需求分析两个阶段任务结束时生成的，所以文档要包含所有需求。在此阶段先要从软件工程和文档管理的角度出发依据相关的标准审核需求文档内容，确定需求文档内容是否完整。对需求文档中存留问题进行修改的工作。 需求确认阶段需求确认主要是针对《需求规格说明书》的评审，保证需求符合优秀需求成熟的特征，并且符合好的需求规格说明的特征。在需求确认阶段需要保证以下几点： （1）软件需求规格说明正确描述了预期的满足各方涉众需求的系统能力和特征。 （2）从系统需求、业务规则或其他来源中正确的推导出软件需求。 （3）需求是完整的、高质量的。 （4）需求的表示在所有地方都是一致的。 （5）需求为继续进行产品设计和构造提供充分的基础。 需求跟踪阶段与需求复用阶段需求跟踪是指通过比较需求文档与后续工作成果之间的对应关系，确保产品依据需求文档进行开发，建立与维护“需求——设计——编程——测试”之间的一致性，确保所有工作成果符合用户需求。需求跟踪是一项需要进行大量手工劳动的任务，在系统开发和维护的过程中一定要随时对跟踪联系链信息进行更新。需求跟踪能力的好坏会直接影响产品质量，降低维护成本，容易实现复用，同时，需求跟踪还需要建设方的大力支持。 需求复用阶段在软件项目实施过程中，许多不同项目间存在着许多相似的需求，尤其是类型相同的项目在不同的用户群众的实施中，需求的相似性就更加明显、更加普遍了。有了需求复用，建设方就能快速的形成一个需求的原型，这样，后期的需求工作只需要在此原型的基础上进行修改、扩充和完善即可，大大提高了需求分析的工作进度。所以，对于需求的复用就需要加以重视。对于需求复用，首要责任就是要提取可复用的需求，对需求复用的理解和扩充。其次就是要保证需求复用不存在冲突。 需求变更控制阶段需求变更在软件项目开发中是不可避免的。无休止的需求变更只会造成各种资源无休止的浪费，但是其中也不乏有许多是必要的、合理的需求变更。对于需求变更，首先是要尽量及早的发现，以避免更大的损失。其次，是要采取相应的、合理的变更管理制度和流程，这样同样可以降低需求变更带来的风险。 版本控制阶段版本控制是管理需求规格说明和其他项目文档必不可少的一个方面，也是需求变更文档化管理的最有效办法。可以详细记录发生需求变更的需求文档版本的版本，发生变更的原因，变更发生的控制记录，并对变更后的需求文档进行唯一版本号的标识。使得每个成员都能及时访问最新版本的需求文档。实施版本控制的基础是需求基线，所谓需求基线就是项目组成员一经承诺将在某一特定产品版本中实现的功能性和非功能性需求的集合。需求基线的确定可以保证项目的涉众各方可以对发布的产品中希望具有的功能和属性有一个一致的理解。 分层数据流模型用例和场景建模及其UML表达（用例图、活动图、泳道图、顺序图）数据模型建模及其UML表达（类图）行为模型建模及其UML表达（状态机图）。三、软件设计与构造软件体系结构及体系结构风格的概念；设计模式的概念；模块化设计的基本思想及概念（抽象、分解、模块化、封装、信息隐藏、功能独立）；软件重构的概念；软件体系结构的UML建模（包图、类图、构件图、顺序图、部署图）；接口的概念；面向对象设计原则（开闭原则、Liskov替换原则、依赖转置原则、接口隔离原则）；内聚与耦合的概念、常见的内聚和耦合类型。 四、软件测试软件测试及测试用例的概念；单元测试、集成测试、确认测试、系统测试、回归测试的概念；调试的概念、调试与测试的关系；测试覆盖度的概念；白盒测试、黑盒测试的概念；代码圈复杂度的计算方法；白盒测试中的基本路径测试方法；黑盒测试中的等价类划分方法。]]></content>
      <categories>
        <category>复习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[详解神经网络]]></title>
    <url>%2F2018%2F07%2F20%2F%E8%AF%A6%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[详解神经网络神经网络的结构神经网络由三部分组成，分别是最左边的输入层，隐藏层（实际应用中远远不止一层）和最右边的输出层。层与层之间用线连接在一起，每条连接线都有一个对应的权重值 w，除了输入层，一般来说每个神经元还有对应的偏置 b。 除了输入层的神经元，每个神经元都会有加权求和得到的输入值 z 和将 z 通过 Sigmoid 函数（也即是激活函数）非线性转化后的输出值 a，他们之间的计算公式如下其中，公式里面的变量l和j表示的是第 l 层的第 j 个神经元，ij 则表示从第 i 个神经元到第 j 个神经元之间的连线，w 表示的是权重，b 表示的是偏置，后面这些符号的含义大体上与这里描述的相似，所以不会再说明。下面的 Gif 动图可以更加清楚每个神经元输入输出值的计算方式（注意，这里的动图并没有加上偏置，但使用中都会加上）使用激活函数的原因是因为线性模型（无法处理线性不可分的情况）的表达能力不够，所以这里通常需要加入 Sigmoid 函数来加入非线性因素得到神经元的输出值。 可以看到 Sigmoid 函数的值域为 (0,1) ，若对于多分类任务，输出层的每个神经元可以表示是该分类的概率。当然还存在其他的激活函数，他们的用途和优缺点也都各异。 BP 算法执行的流程（前向传递和逆向更新）在手工设定了神经网络的层数，每层的神经元的个数，学习率 η（下面会提到）后，BP 算法会先随机初始化每条连接线权重和偏置，然后对于训练集中的每个输入 x 和输出 y，BP 算法都会先执行前向传输得到预测值，然后根据真实值与预测值之间的误差执行逆向反馈更新神经网络中每条连接线的权重和每层的偏好。在没有到达停止条件的情况下重复上述过程。 其中，停止条件可以是下面这三条 权重的更新低于某个阈值的时候 预测的错误率低于某个阈值 达到预设一定的迭代次数 譬如说，手写数字识别中，一张手写数字1的图片储存了28*28 = 784个像素点，每个像素点储存着灰度值(值域为[0,255])，那么就意味着有784个神经元作为输入层，而输出层有10个神经元代表数字0~9，每个神经元取值为0~1，代表着这张图片是这个数字的概率。 每输入一张图片（也就是实例），神经网络会执行前向传输一层一层的计算到输出层神经元的值，根据哪个输出神经元的值最大来预测输入图片所代表的手写数字。 然后根据输出神经元的值，计算出预测值与真实值之间的误差，再逆向反馈更新神经网络中每条连接线的权重和每个神经元的偏好。 前向传输（Feed-Forward） 从输入层=&gt;隐藏层=&gt;输出层，一层一层的计算所有神经元输出值的过程。 逆向反馈（Back Propagation） 因为输出层的值与真实的值会存在误差，我们可以用均方误差来衡量预测值和真实值之间的误差。 均方误差 逆向反馈的目标就是让E函数的值尽可能的小，而每个神经元的输出值是由该点的连接线对应的权重值和该层对应的偏好所决定的，因此，要让误差函数达到最小，我们就要调整w和b值， 使得误差函数的值最小。 权重和偏置的更新公式对目标函数 E 求 w 和 b 的偏导可以得到 w 和 b 的更新量，下面拿求 w 偏导来做推导。其中 η 为学习率，取值通常为 0.1 ~ 0.3,可以理解为每次梯度所迈的步伐。注意到 w_hj 的值先影响到第 j 个输出层神经元的输入值a，再影响到输出值y，根据链式求导法则有： 使用链式法则展开对权重求偏导 根据神经元输出值 a 的定义有：对函数 z 求 w 的偏导 Sigmoid 求导数的式子如下，从式子中可以发现其在计算机中实现也是非常的方便： 所以 则权重 w 的更新量为： 类似可得 b 的更新量为：但这两个公式只能够更新输出层与前一层连接线的权重和输出层的偏置，原因是因为 δ 值依赖了真实值y这个变量，但是我们只知道输出层的真实值而不知道每层隐藏层的真实值，导致无法计算每层隐藏层的 δ 值，所以我们希望能够利用 l+1 层的 δ 值来计算 l 层的 δ 值，而恰恰通过一些列数学转换后可以做到，这也就是逆向反馈名字的由来，公式如下:从式子中我们可以看到，我们只需要知道下一层的权重和神经元输出层的值就可以计算出上一层的 δ 值，我们只要通过不断的利用上面这个式子就可以更新隐藏层的全部权重和偏置了。 在推导之前请先观察下面这张图：首先我们看到 l 层的第 i 个神经元与 l+1 层的所有神经元都有连接，那么我们可以将 δ 展开成如下的式子：也即是说我们可以将 E 看做是 l+1 层所有神经元输入值的 z 函数，而上面式子的 n 表示的是 l+1 层神经元的数量，再进行化简后就可以得到上面所说的式子。 卷积神经网络卷积神经网络采用了三种基本概念：局部感受野（local receptive fields），共享权重（shared weights），和混合（pooling）。让我们逐个看下： 局部感受野在之前看到的全连接层的网络中，输入被描绘成纵向排列的神经元。但在一个卷积网络中，把输入看作是一个2828的方形排列的神经元更有帮助，其值对应于我们用作输入的28 28 的像素光强度：和通常一样，我们把输入像素连接到一个隐藏神经元层。但是我们不会把每个输入像素连接到每个隐藏神经元。相反，我们只是把输入图像进行小的，局部区域的连接。 说的确切一点，第一个隐藏层中的每个神经元会连接到一个输入神经元的一个小区域，例如，一个5*5的区域，对应于25个输入像素。所以对于一个特定的隐藏神经元，我们可能有看起来像这样的连接：这个输入图像的区域被称为隐藏神经元的局部感受野。它是输入像素上的一个小窗口。 每个连接学习一个权重。而隐藏神经元同时也学习一个总的偏置。你可以把这个特定的隐藏神经元看作是在学习分析它的局部感受野。 我们然后在整个输入图像上交叉移动局部感受野。对于每个局部感受野，在第一个隐藏层中有一个不同的隐藏神经元。为了正确说明，让我们从左上角开始一个局部感受野： 然后我们往右一个像素（即一个神经元）移动局部感受野，连接到第二个隐藏神经元：如此重复，构建起第一个隐藏层。注意如果我们有一个2828的输入图像，5 5的局部感受野，那么隐藏层中就会有24 * 24个神经元。这是因为在抵达右边（或者底部）的输入图像之前，我们只能把局部感受野横向移动23个神经元（或者往下23个神经元）。 我显示的局部感受野每次移动一个像素。实际上，有时候会使用不同的跨距。例如，我可以往右（或下）移动2个像素的局部感受野，这种情况下我们使用了1个跨距。在这章里我们大部分时候会固定使用1的跨距，但是值得知道人们有时用不同的跨距试验2。 共享权重和偏置：我已经说过每个隐藏神经元具有一个偏置和连接到它的局部感受野的55权重。我没有提及的是我们打算24 24隐藏神经元中的每一个使用相同的权重和偏置。换句话说，对第j,k个隐藏神经元，输出为： 这意味着第一个隐藏层的所有神经元检测完全相同的特征，只是在输入图像的不同位置。要明白为什么是这个道理，把权重和偏置设想成隐藏神经元可以挑选的东西，例如，在一个特定的局部感受野的垂直边缘。这种能力在图像的其它位置也很可能是有用的。因此，在图像中应用相同的特征检测器是非常有用的。用稍微更抽象的术语，卷积网络能很好地适应图像的平移不变性：例如稍稍移动一幅猫的图像，它仍然是一幅猫的图像。 因为这个原因，我们有时候把从输入层到隐藏层的映射称为一个特征映射。我们把定义特征映射的权重称为共享权重。我们把以这种方式定义特征映射的偏置称为共享偏置。共享权重和偏置经常被称为一个卷积核或者滤波器。在文献中，人们有时以稍微不同的方式使用这些术语，对此我不打算去严格区分；稍后我们会看一些具体的例子。 目前我描述的网络结构只能检测一种局部特征的类型。为了完成图像识别我们需要超过一个的特征映射。所以一个完整的卷积层由几个不同的特征映射组成： 共享权重和偏置的一个很大的优点是，它大大减少了参与的卷积网络的参数 池化/采样层 除了刚刚描述的卷积层，卷积神经网络也包含池化层（pooling layers）。池化层通常紧接着在卷积层之后使用。它要做的是简化从卷积层输出的信息。 详细地说，一个池化层取得从卷积层输出的每一个特征映射6并且从它们准备一个凝缩的特征映射。例如，混合层的每个单元可能概括了前一层的一（比如）22 的区域。作为一个具体的例子，一个常见的混合的程序被称最大值混合（max-pooling）。在最大池化层中，一个pooling单元简单地输出其2 2输入区域的最大激活值，正如下图说明的： 注意既然从卷积层有24 24个神经元输出，池化后我们得到12 12个神经元。 正如上面提到的，卷积层通常包含超过一个特征映射。我们将最大值混合分别应用于每一个特征映射。所以如果有三个特征映射，组合在一起的卷积层和池化层层看起来像这样： 综合在一起： 我们现在可以把这些思想都放在一起来构建一个完整的卷积神经网络。它和我们刚看到的架构相似，但是有额外的一层 10个输出神经元，对应于个可能的 MNIST 数字（’0’，’1’，’2’等）：]]></content>
  </entry>
  <entry>
    <title><![CDATA[反向传播]]></title>
    <url>%2F2018%2F03%2F20%2F%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD(backpropagation)%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%2F</url>
    <content type="text"><![CDATA[反向传播(backpropagation)是如何工作的反向传播算法最早于上世纪70年代被提出，但是直到1986年，由David Rumelhart, Geoffrey Hinton, 和Ronald Williams联合发表了一篇著名论文之后，人们才完全认识到这个算法的重要性。这篇论文介绍了几种神经网络，在这些网络的学习中，反向传播算法比之前提出的方法都要快。这使得以前用神经网络不可解的一些问题，现在可以通过神经网络来解决。今天，反向传播算法是神经网络学习过程中的关键（workhorse）所在。反向传播算法的核心是一个偏微分表达式，表示代价函数对网络中的权重（或者偏置）求偏导。这个式子告诉我们，当我们改变权重和偏置的时候，代价函数的值变化地有多快。尽管这个式子有点复杂，这个式子也是很漂亮的，它的每一个部分都有自然的，直觉上的解释。因此，反向传播不仅仅是一种快速的学习算法，它能够让我们详细深入地了解改变权重和偏置的值是如何改变整个网络的行为的。这是非常值得深入学习的。 关于代价函数的两个架设反向传播算法的目标是计算代价函数对神经网络中出现的所有权重和偏置的偏导数和 第一条假设是代价函数能够被写成的形式，其中是每个独立训练样本的代价函数。在代价函数为平方代价函数的情况下，一个训练样本的代价是。该假设对于本书中涉及到的其它所有代价函数都成立。我们需要上述假设的原因是，反向传播实际上是对单个训练数据计算偏导数和。然后通过对所有训练样本求平均值获得和。事实上，有了这个假设，我们可以认为训练样本是固定的，然后把代价去掉下标表示为。最终我们会重新把加回公式，但目前为了简便我们将它隐去。 第二条假设是它可以写成关于神经网络输出结果的函数：平方代价函数满足该要求，因为单一训练样本的二次代价可以表示为：这是一个关于输出激活值的函数。显然，该代价函数也依赖于期望的输出，所以你可能疑惑为什么我们不把代价视为关于的函数。记住，输入的训练样本是固定的，因此期望的输出也是固定的。需要注意，我们不能通过改变权值或偏置来修改它，换句话说，它不是神经网络所学习的东西。所以把视为只关于输出的函数是有道理的。在该函数中只是帮助定义函数的参数。 Hadamard积反向传播算法是以常见线性代数操作为基础——诸如向量加法，向量与矩阵乘法等运算。但其中一个操作相对不是那么常用。具体来讲，假设和是两个有相同维数的向量。那么我们用来表示两个向量的对应元素(elementwise)相乘。因此的元素。例如，这种对应元素相乘有时被称为Hadamard积（Hadamard product）或Schur积(Schur product)。我们将称它为Hadamard积。优秀的矩阵库通常会提供Hadamard积的快速实现，这在实现反向传播时将会有用。 反向传播背后的四个基本等式反向传播(backpropagation)能够帮助解释网络的权重和偏置的改变是如何改变代价函数的。归根结底，它的意思是指计算偏导数和。但是为了计算这些偏导数，我们首先介绍一个中间量，，我们管它叫做层的神经元的错误量(error)。反向传播会提供给我们一个用于计算错误量的流程，能够把和、关联起来。为了理解错误量是如何定义的，想象一下在我们的神经网络中有一个恶魔： 这个恶魔位于层的神经元。当神经元的输入进入时，这个恶魔扰乱神经元的操作。它给神经元的加权输入添加了一点改变，这就导致了神经元的输出变成了，而不是之前的。这个改变在后续的网络层中传播，最终使全部代价改变了。而今，这个恶魔变成了一个善良的恶魔，它试图帮助你改善代价，比如，它试图找到一个能够让代价变小。假设是一个很大的值（或者为正或者为负）。然后这个善良的恶魔可以通过选择一个和符号相反的使得代价降低。相比之下，如果接近于0，那么这个恶魔几乎不能通过扰乱加权输入改善多少代价。在一定范围内这个善良的恶魔就可以分辨出，这个神经元已经接近于最佳状态1。至此，有了一种启发式的感觉：可以用来衡量神经元里的错误量。 1.输出层中关于错误量的等式（计算最后一层神经网络产生的错误）：推导过程 这是一种非常自然的表达。右侧的第一项，就是用于测量输出激活代价改变有多快的函数。举个例子，如果并不太依赖于某个特别的输出神经元，那么就会很小，这是我们所期望的。右侧的第二项，用于测量处的激活函数改变有多快。你应该注意到(BP1)中的每一项都是容易计算的。特别的，当计算神经网络的行为时就计算了，而计算也仅仅是一小部分额外的开销。当然了，的确切形式依赖于代价函数的形式。然而，如果提供了代价函数，大家也应该知道计算也不会有什么困难。举个例子，如果我们使用平方代价函数，即，那么，这显然很容易计算。等式(BP1)是的分量形式。它是一个完美的表达式，但并不是我们想要的基于矩阵的形式，那种矩阵形式可以很好的用于反向传播。然而，我们可以很容易把等式重写成基于矩阵的形式，就像：其中，是一个向量，它是由组成的。你可以把看做现对于输出激活的的改变速率。很容易看出来等式(BP1)和(BP1a)是等价的，基于这个原因我们从现在开始将使用(BP1)交替地指代两个等式。举个例子，在使用平方代价函数的情况下我们有，所以完整的基于矩阵的(BP1)的形式变为：就像你所看到的，表达式里的每一项都拥有一个漂亮的向量形式，并且很容易使用一个库来计算，比如Numpy。 2.依据下一层错误量获取错误量的等式（由后往前，计算每一层神经网络产生的错误）： 其中，是层的权重矩阵的转置。这个等式看着有些复杂，但是每一项都有很好的解释。假设我们知道层的错误量。当我们使用转置权值矩阵的时候，我们可以凭借直觉认为将错误反向（backward）移动穿过网络，带给我们某种测量层输出的错误量方法。然后我们使用Hadamard乘积。这就是将错误量反向移动穿过层的激活函数，产生了层的加权输入的错误量。通过结合(BP2)和(BP1)我们可以计算网络中任意一层的错误量。我们开始使用(BP1)来计算，然后应用等式(BP2)来计算，然后再次应用等式(BP2)来计算，以此类推，反向通过网络中的所有路径。 3.网络的代价函数相对于偏置的改变速率的等式（计算偏置的梯度）： 也就是说，错误量完全等于改变速率。这是一个很好的消息，因为(BP1)和(BP2)已经告诉我们如何计算。我们把(BP3)重写成如下的简略形式：这可以理解成可以和偏置在相同的神经元中被估计。 4.网络的代价函数相对于权重的改变速率的等式（计算权重的梯度）：： 这个等式告诉我们如何依据和来计算偏导，而这两个量我们已经知道如何计算了。这个等式可以重写成如下含有少量下标的形式：可以这么理解，是神经元的激活量，输入到权重中，是神经元的错误量，从权重输出。观察这个权重，两个神经元通过这个权重连接起来，我们可以这样描画出来： 等式(32)的一个很好的结论是当激活量很小的时候，，梯度项也将会趋近于很小。在这种情况下，我们说权重学习得很慢，也就是说在梯度下降的时候并没有改变很多。换而言之，等式(BP4)的一个结果就是从低激活量神经元里输出的权重会学习缓慢。 反向传播算法反向传播等式为我们提供了一个计算代价函数梯度的方法。下面让我们明确地写出该算法： 输入 :计算输入层相应的激活函数值。 正向传播：对每个，计算和。 输出误差 ：计算向量。 将误差反向传播：对每个计算 输出：代价函数的梯度为和通过以上算法就能看出它为什么叫反向传播算法。我们从最后一层开始，反向计算错误向量。在神经网络中反向计算误差可能看起来比较奇怪。但如果回忆反向传播的证明过程，会发现反向传播的过程起因于代价函数是关于神经网络输出值的函数。为了了解代价函数是如何随着前面的权重和偏置改变的，我们必须不断重复应用链式法则，通过反向的计算得到有用的表达式。 为什么说反向传播算法很高效？为什么说反向传播算法很高效？要回答这个问题，让我们来考虑另一种计算梯度的方式。设想现在是神经网络研究的早期阶段，大概是在上世纪50年代或60年代左右，并且你是第一个想到使用梯度下降方法来进行训练的人！但是要实现这个想法，你需要一种计算代价函数梯度的方式。你回想了你目前关于演算的知识，决定试一下是否能用链式法则来计算梯度。但是琢磨了一会之后发现，代数计算看起来非常复杂，你也因此有些失落。所以你尝试着寻找另一种方法。你决定把代价单独当做权重的函数（我们一会再来讨论偏置）。将权重写作，并且要对某个权重计算。一个很明显的计算方式是使用近似：其中是一个大于零的小正数。换句话说，我们可以通过计算两个差距很小的wj的代价，然后利用等式(46)来估计。我们可以利用相同的思想来对偏置求偏导。这种方式看起来很不错。它的概念很简单，实现起来也很简单，只需要几行代码就可以。当然了，他看起来要比使用链式法则来计算梯度靠谱多了！然而遗憾的是，虽然这种方式看起来很美好，但当用代码实现之后就会发现，它实在是太慢了。要理解其中的原因的话，设想在我们的神经网络中有一百万个权重，对于每一个不同的权重，为了计算，我们需要计算。这意味着为了计算梯度，我们需要计算一百万次代价函数，进而对于每一个训练样例，都需要在神经网络中前向传播一百万次。我们同样需要计算，因此总计需要一百万零一次前向传播。反向传播的优点在于它仅利用一次前向传播就可以同时计算出所有的偏导，随后也仅需要一次反向传播。大致来说，反向传播算法所需要的总计算量与两次前向传播的计算量基本相等（这应当是合理的，但若要下定论的话则需要更加细致的分析。合理的原因在于前向传播时主要的计算量在于权重矩阵的乘法计算，而反向传播时主要的计算量在于权重矩阵转置的乘法。很明显，它们的计算量差不多）。这与基于等式(46)的方法所需要的一百万零一次前向传播相比，虽然反向传播看起来更复杂一些，但它确实更更更更更快。这种加速方式在1986年首次被人们所重视，极大地拓展了神经网络能够适用的范围，也导致了神经网络被大量的应用。当然了，反向传播算法也不是万能的。在80年代后期，人们终于触及到了性能瓶颈，在利用反向传播算法来训练深度神经网络（即具有很多隐含层的网络）时尤为明显。在本书后面的章节中我们将会看到现代计算机以及一些非常聪明的新想法是如何让反向传播能够用来训练深度神经网络的。 反向传播：整体描述正如我之前所阐述的，反向传播涉及了两个谜题。第一个谜题是，这个算法究竟在做什么？我们之前的描述是将错误量从输出层反向传播。但是，我们是否能够更加深入，对这些矩阵、向量的乘法背后作出更加符合直觉的解释？第二个谜题是，人们一开始是如何发现反向传播算法的？按照算法流程一步步走下来，或者证明算法的正确性，这是一回事。但这并不代表你能够理解问题的本质从而能够从头发现这个算法。是否有一条合理的思维路线使你能够发现反向传播算法？在本节中，我会对这两个谜题作出解释。为了更好地构建的反向传播算法在做什么的直觉，让我们假设我们对网络中的某个权重做出了一个小的改变量： 这个改变量会导致与其相关的神经元的输出激活值的改变： 以此类推，会引起下一层的所有激活值的改变： 这些改变会继续引起再下一层的改变、下下层…依次类推，直到最后一层，然后引起代价函数的改变： 代价函数的改变量与最初权重的改变量是有关的，关系是下面这个等式这表明了计算的一种可能方法是，计算上的一个小改变量经过正向传播，对引起了多大的改变量。如果我们能够通过小心翼翼的计算做到这点，那我们就可以计算出。让我们尝试来写一下计算过程。改变量对层的第个神经元的激活值带来了的改变量。它的大小是激活值改变量会引起下一层（第层）的所有激活值都改变。我们先关注其中的一个结点，， 它产生的改变量是：将等式(48)带入其中，得到：当然，改变量会继续造成下一层的激活值的改变。实际上，我们可以想象一条从到的路径，其中每一个结点的激活值的改变都会引起下一层的激活值的改变，最终引起输出层的代价的改变。如果这条路径是，那么最终的改变量是这样，我们使用了一系列的形式的项，对应了路径上的每一个结点，包括最终项。这就计算出了在神经网络的这条路径上，最初的改变量引起了多大的改变。当然，由的改变量影响代价改变的路径选择是很多的，我们现在只考虑了其中的一条路径。为了计算最终总共的改变量，很显然我们应该对所有可能的路径对其带来的改变量进行求和：其中，我们对每条路径中所有出现的神经元都进行求和。与等式(47)进行比较，我们得到：等式(53)看上去很复杂。不过，它在直觉上很容易理解。我们计算出了相对于网络中的一个权重的变化速率。这个等式告诉我们的是，每一条连接两个神经元的边都可以对应一个变化速率，这个变化速率的大小是后一个神经元对前一个神经元的偏导。连接第一个权重和第一个神经元的边对应的变化速率是。一条路径对应的变化速率恰好是路径上的变化速率的连乘。总变化速率是从起始权重到最终代价上的所有可能的路径的变化速率的总和。用图片来说明这个过程，对于一条路径来说： 目前为止我所阐述的是一种启发式的观点，当你困惑于神经网络中的权重时，可以通过这种观点来思考。下面我会给你一些简要的思路使你可以更进一步的完善这个观点。首先，你可以显式地计算出等式53中的每一项的偏导表达式。这很容易做到，只需要一点计算量就行。做完之后，你可以尝试将所有的求和通过矩阵的形式来表示。这个过程会有一点无聊，并且需要一些毅力，但是不会特别的困难。随后，你可以尝试尽可能的将表达式简化，最终你会发现你得到了反向传播算法！所以，你可以将反向传播算法看作是一种对所有路径上的所有变化率进行求和的方法。或者用另外一种方式来说，反向传播算法是一种很聪明的方法，当小扰动沿着网络传播、到达输出并影响代价的过程中，它能够记录其对相应权重（和偏置）的影响量。我的解释到此为止了。这可能有点复杂，并且需要仔细思考所有的细节。如果你乐于接受挑战，你可能会很享受这个过程。如果不是，我希望我的这些想法能够给你一些关于反向传播在做什么的启发。那关于其它的谜题呢——反向传播最初是如何被发现的？实际上，如果你一路看下来我的阐述，你能够找到关于反向传播算法的一种证明。不幸的是，完整的证明实际上比我在本章的描述更长更复杂。那这个相对更简单（但更玄虚）的证明是如何发现的呢？当你把试图把完整的证明中的所有细节写出来时，你会发现有一些很显然能够被简化的形式。你做完这些简化，会得到一个简短一些的证明。然后你又会发现一些可以简化的内容。当你重复几次这个过程之后，你会得到本章中的这个简短的证明，但是它有点晦涩，因为其中所有复杂的结构都被简化掉了！我希望你能够相信我，完整的证明与本章中简短的证明没有什么本质区别。我只是对证明过程做了很多简化的工作。 转自gitbook Neural Networks and Deep Learning 翻译https://www.gitbook.com/book/hit-scir/neural-networks-and-deep-learning-zh_cn/details]]></content>
  </entry>
</search>
